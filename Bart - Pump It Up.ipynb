{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "required <- c('ggplot2', 'plyr', 'dplyr',\n",
    "              'caret', 'reshape2', 'ROCR', 'e1071', 'randomForest', 'gbm',\n",
    "              'car', 'missForest', 'ggmap', 'lubridate', 'Amelia', 'magrittr',\n",
    "              'doMC', 'pROC')\n",
    "installed <- rownames(installed.packages())\n",
    "tobeinstalled <- required[!(required %in% installed)]\n",
    "print(paste('Installing', tobeinstalled))\n",
    "install.packages(tobeinstalled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "install.packages('bartMachine_1.2.1.tar.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading required package: Rcpp\n",
      "## \n",
      "## Amelia II: Multiple Imputation\n",
      "## (Version 1.7.4, built: 2015-12-05)\n",
      "## Copyright (C) 2005-2016 James Honaker, Gary King and Matthew Blackwell\n",
      "## Refer to http://gking.harvard.edu/amelia/ for more information\n",
      "## \n",
      "\n",
      "Attaching package: ‘plyr’\n",
      "\n",
      "The following object is masked from ‘package:lubridate’:\n",
      "\n",
      "    here\n",
      "\n"
     ]
    }
   ],
   "source": [
    "source('common.R')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading required package: lattice\n",
      "Loading required package: ggplot2\n"
     ]
    }
   ],
   "source": [
    "library(caret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trainset.labels <- read.csv('trainset_labels.csv', na.strings = \"\")\n",
    "statusGroups <- dummyVars(~ status_group, data = trainset.labels)\n",
    "trainset.labels <- cbind(trainset.labels, data.frame(predict(statusGroups, trainset.labels)))\n",
    "\n",
    "trainset.values <- read.csv('trainset_values.csv', na.strings = \"\") %>%\n",
    "  prepareDataSet('train')\n",
    "\n",
    "testset.values <- read.csv('testset_values.csv', na.strings = \"\") %>% \n",
    "  prepareDataSet('test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th></th><th scope=col>id</th><th scope=col>amount_tsh</th><th scope=col>date_recorded</th><th scope=col>funder</th><th scope=col>gps_height</th><th scope=col>installer</th><th scope=col>longitude</th><th scope=col>latitude</th><th scope=col>wpt_name</th><th scope=col>num_private</th><th scope=col>ellip.h</th><th scope=col>source</th><th scope=col>source_type</th><th scope=col>source_class</th><th scope=col>waterpoint_type</th><th scope=col>waterpoint_type_group</th><th scope=col>date_recorded_year</th><th scope=col>date_recorded_year_ago</th><th scope=col>date_recorded_month</th><th scope=col>date_recorded_day</th><th scope=col>type</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>1</th><td>69572</td><td>6000</td><td>2011-03-14</td><td>Roman</td><td>1390</td><td>Roman</td><td>34.93809</td><td>-9.856322</td><td>none</td><td>0</td><td>⋯</td><td>spring</td><td>spring</td><td>groundwater</td><td>communal standpipe</td><td>communal standpipe</td><td>2011</td><td>4</td><td>3</td><td>14</td><td>train</td></tr>\n",
       "\t<tr><th scope=row>2</th><td>8776</td><td>0</td><td>2013-03-06</td><td>Grumeti</td><td>1399</td><td>GRUMETI</td><td>34.69877</td><td>-2.147466</td><td>Zahanati</td><td>0</td><td>⋯</td><td>rainwater harvesting</td><td>rainwater harvesting</td><td>surface</td><td>communal standpipe</td><td>communal standpipe</td><td>2013</td><td>2</td><td>3</td><td>6</td><td>train</td></tr>\n",
       "\t<tr><th scope=row>3</th><td>34310</td><td>25</td><td>2013-02-25</td><td>Lottery Club</td><td>686</td><td>World vision</td><td>37.46066</td><td>-3.821329</td><td>Kwa Mahundi</td><td>0</td><td>⋯</td><td>dam</td><td>dam</td><td>surface</td><td>communal standpipe multiple</td><td>communal standpipe</td><td>2013</td><td>2</td><td>2</td><td>25</td><td>train</td></tr>\n",
       "\t<tr><th scope=row>4</th><td>67743</td><td>0</td><td>2013-01-28</td><td>Unicef</td><td>263</td><td>UNICEF</td><td>38.48616</td><td>-11.1553</td><td>Zahanati Ya Nanyumbu</td><td>0</td><td>⋯</td><td>machine dbh</td><td>borehole</td><td>groundwater</td><td>communal standpipe multiple</td><td>communal standpipe</td><td>2013</td><td>2</td><td>1</td><td>28</td><td>train</td></tr>\n",
       "\t<tr><th scope=row>5</th><td>19728</td><td>0</td><td>2011-07-13</td><td>Action In A</td><td>0</td><td>Artisan</td><td>31.13085</td><td>-1.825359</td><td>Shuleni</td><td>0</td><td>⋯</td><td>rainwater harvesting</td><td>rainwater harvesting</td><td>surface</td><td>communal standpipe</td><td>communal standpipe</td><td>2011</td><td>4</td><td>7</td><td>13</td><td>train</td></tr>\n",
       "\t<tr><th scope=row>6</th><td>9944</td><td>20</td><td>2011-03-13</td><td>Mkinga Distric Coun</td><td>0</td><td>DWE</td><td>39.1728</td><td>-4.765587</td><td>Tajiri</td><td>0</td><td>⋯</td><td>other</td><td>other</td><td>unknown</td><td>communal standpipe multiple</td><td>communal standpipe</td><td>2011</td><td>4</td><td>3</td><td>13</td><td>train</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|lllllllllllllllllllllllllllllllllllllllllllll}\n",
       "  & id & amount_tsh & date_recorded & funder & gps_height & installer & longitude & latitude & wpt_name & num_private & ellip.h & source & source_type & source_class & waterpoint_type & waterpoint_type_group & date_recorded_year & date_recorded_year_ago & date_recorded_month & date_recorded_day & type\\\\\n",
       "\\hline\n",
       "\t1 & 69572 & 6000 & 2011-03-14 & Roman & 1390 & Roman & 34.93809 & -9.856322 & none & 0 & ⋯ & spring & spring & groundwater & communal standpipe & communal standpipe & 2011 & 4 & 3 & 14 & train\\\\\n",
       "\t2 & 8776 & 0 & 2013-03-06 & Grumeti & 1399 & GRUMETI & 34.69877 & -2.147466 & Zahanati & 0 & ⋯ & rainwater harvesting & rainwater harvesting & surface & communal standpipe & communal standpipe & 2013 & 2 & 3 & 6 & train\\\\\n",
       "\t3 & 34310 & 25 & 2013-02-25 & Lottery Club & 686 & World vision & 37.46066 & -3.821329 & Kwa Mahundi & 0 & ⋯ & dam & dam & surface & communal standpipe multiple & communal standpipe & 2013 & 2 & 2 & 25 & train\\\\\n",
       "\t4 & 67743 & 0 & 2013-01-28 & Unicef & 263 & UNICEF & 38.48616 & -11.1553 & Zahanati Ya Nanyumbu & 0 & ⋯ & machine dbh & borehole & groundwater & communal standpipe multiple & communal standpipe & 2013 & 2 & 1 & 28 & train\\\\\n",
       "\t5 & 19728 & 0 & 2011-07-13 & Action In A & 0 & Artisan & 31.13085 & -1.825359 & Shuleni & 0 & ⋯ & rainwater harvesting & rainwater harvesting & surface & communal standpipe & communal standpipe & 2011 & 4 & 7 & 13 & train\\\\\n",
       "\t6 & 9944 & 20 & 2011-03-13 & Mkinga Distric Coun & 0 & DWE & 39.1728 & -4.765587 & Tajiri & 0 & ⋯ & other & other & unknown & communal standpipe multiple & communal standpipe & 2011 & 4 & 3 & 13 & train\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "     id amount_tsh date_recorded              funder gps_height    installer\n",
       "1 69572       6000    2011-03-14               Roman       1390        Roman\n",
       "2  8776          0    2013-03-06             Grumeti       1399      GRUMETI\n",
       "3 34310         25    2013-02-25        Lottery Club        686 World vision\n",
       "4 67743          0    2013-01-28              Unicef        263       UNICEF\n",
       "5 19728          0    2011-07-13         Action In A          0      Artisan\n",
       "6  9944         20    2011-03-13 Mkinga Distric Coun          0          DWE\n",
       "  longitude   latitude             wpt_name num_private                   basin\n",
       "1  34.93809  -9.856322                 none           0              Lake Nyasa\n",
       "2  34.69877  -2.147466             Zahanati           0           Lake Victoria\n",
       "3  37.46066  -3.821329          Kwa Mahundi           0                 Pangani\n",
       "4  38.48616 -11.155298 Zahanati Ya Nanyumbu           0 Ruvuma / Southern Coast\n",
       "5  31.13085  -1.825359              Shuleni           0           Lake Victoria\n",
       "6  39.17280  -4.765587               Tajiri           0                 Pangani\n",
       "   subvillage  region region_code district_code       lga       ward population\n",
       "1    Mnyusi B  Iringa          11             5    Ludewa   Mundindi        109\n",
       "2     Nyamara    Mara          20             2 Serengeti      Natta        280\n",
       "3     Majengo Manyara          21             4 Simanjiro    Ngorika        250\n",
       "4  Mahakamani  Mtwara          90            63  Nanyumbu   Nanyumbu         58\n",
       "5  Kyanyamisa  Kagera          18             1   Karagwe Nyakasimbi          0\n",
       "6 Moa/Mwereme   Tanga           4             8    Mkinga        Moa          1\n",
       "  public_meeting             recorded_by scheme_management\n",
       "1           True GeoData Consultants Ltd               VWC\n",
       "2           <NA> GeoData Consultants Ltd             Other\n",
       "3           True GeoData Consultants Ltd               VWC\n",
       "4           True GeoData Consultants Ltd               VWC\n",
       "5           True GeoData Consultants Ltd              <NA>\n",
       "6           True GeoData Consultants Ltd               VWC\n",
       "                  scheme_name permit construction_year extraction_type\n",
       "1                       Roman  False              1999         gravity\n",
       "2                        <NA>   True              2010         gravity\n",
       "3 Nyumba ya mungu pipe scheme   True              2009         gravity\n",
       "4                        <NA>   True              1986     submersible\n",
       "5                        <NA>   True                NA         gravity\n",
       "6                   Zingibali   True              2009     submersible\n",
       "  extraction_type_group extraction_type_class management management_group\n",
       "1               gravity               gravity        vwc       user-group\n",
       "2               gravity               gravity        wug       user-group\n",
       "3               gravity               gravity        vwc       user-group\n",
       "4           submersible           submersible        vwc       user-group\n",
       "5               gravity               gravity      other            other\n",
       "6           submersible           submersible        vwc       user-group\n",
       "         payment payment_type water_quality quality_group     quantity\n",
       "1   pay annually     annually          soft          good       enough\n",
       "2      never pay    never pay          soft          good insufficient\n",
       "3 pay per bucket   per bucket          soft          good       enough\n",
       "4      never pay    never pay          soft          good          dry\n",
       "5      never pay    never pay          soft          good     seasonal\n",
       "6 pay per bucket   per bucket         salty         salty       enough\n",
       "  quantity_group               source          source_type source_class\n",
       "1         enough               spring               spring  groundwater\n",
       "2   insufficient rainwater harvesting rainwater harvesting      surface\n",
       "3         enough                  dam                  dam      surface\n",
       "4            dry          machine dbh             borehole  groundwater\n",
       "5       seasonal rainwater harvesting rainwater harvesting      surface\n",
       "6         enough                other                other      unknown\n",
       "              waterpoint_type waterpoint_type_group date_recorded_year\n",
       "1          communal standpipe    communal standpipe               2011\n",
       "2          communal standpipe    communal standpipe               2013\n",
       "3 communal standpipe multiple    communal standpipe               2013\n",
       "4 communal standpipe multiple    communal standpipe               2013\n",
       "5          communal standpipe    communal standpipe               2011\n",
       "6 communal standpipe multiple    communal standpipe               2011\n",
       "  date_recorded_year_ago date_recorded_month date_recorded_day  type\n",
       "1                      4                   3                14 train\n",
       "2                      2                   3                 6 train\n",
       "3                      2                   2                25 train\n",
       "4                      2                   1                28 train\n",
       "5                      4                   7                13 train\n",
       "6                      4                   3                13 train"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "head(trainset.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Joining by: id\n"
     ]
    }
   ],
   "source": [
    "#reducedTrainset <- head(join(trainset.values, trainset.labels), 10000)\n",
    "reducedTrainset <- join(trainset.values, trainset.labels)\n",
    "inTrain <- createDataPartition(y=reducedTrainset$status_group, p=0.8, list=FALSE)\n",
    "training <- reducedTrainset[inTrain,]\n",
    "testing <- reducedTrainset[-inTrain,]\n",
    "\n",
    "nzvs <- nzv(training)\n",
    "predictors <- colnames(training)[!(colnames(training) %in% c('id', 'status_group', 'recorded_by', 'type','wpt_name',\n",
    "                                                             'ward', 'lga',\n",
    "                                                             'scheme_name', 'public_meeting', 'gps_height', 'num_private',\n",
    "                                                             'installer', 'subvillage', 'funder', 'permit')) &\n",
    "                                   !grepl('status_group', colnames(training))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "             functional functional needs repair          non functional \n",
       "                   2030                    3454                    1424 "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nmin <- sum(training$status_group == 'functional needs repair')\n",
    "others <- training$status_group != 'functional needs repair'\n",
    "undersampled <- rbind(training[others,][sample.int(sum(others), nmin),],\n",
    "                      training[training$status_group == 'functional needs repair',])\n",
    "\n",
    "table(undersampled$status_group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading required package: rJava\n",
      "Loading required package: car\n",
      "Loading required package: randomForest\n",
      "randomForest 4.6-12\n",
      "Type rfNews() to see new features/changes/bug fixes.\n",
      "\n",
      "Attaching package: ‘randomForest’\n",
      "\n",
      "The following object is masked from ‘package:ggplot2’:\n",
      "\n",
      "    margin\n",
      "\n",
      "Loading required package: missForest\n",
      "Loading required package: foreach\n",
      "Loading required package: itertools\n",
      "Loading required package: iterators\n",
      "Welcome to bartMachine v1.2.1! You have 52.49GB memory available.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bartMachine now using 3 cores.\n"
     ]
    }
   ],
   "source": [
    "options(java.parameters=\"-Xmx55g\")\n",
    "library(bartMachine)\n",
    "set_bart_machine_num_cores(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "3454"
      ],
      "text/latex": [
       "3454"
      ],
      "text/markdown": [
       "3454"
      ],
      "text/plain": [
       "[1] 3454"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nmin <- sum(training$status_group == 'functional needs repair')\n",
    "nmin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fits <- list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#ctrl <- trainControl(method = 'cv', classProbs = TRUE, number = 1, repeats = 1)\n",
    "#fits[[]] <- train(training[,predictors],\n",
    "#                  factor(training[,'status_group.functional'], labels = c('F', 'T')),\n",
    "#                        method = \"bartMachine\",\n",
    "#                        use_missing_data = TRUE,\n",
    "#                        tuneLength = 5,\n",
    "#                        metric = \"ROC\",\n",
    "#                        trControl = ctrl,\n",
    "#                        ## Tell randomForest to sample by strata. Here, \n",
    "#                        ## that means within each class\n",
    "#                       strata = factor(training[,'status_group.functional']),\n",
    "#                        ## Now specify that the number of samples selected\n",
    "#                        ## within each class should be the same\n",
    "#                        sampsize = rep(nmin, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<table width=\"100%\" summary=\"page for bartMachine {bartMachine}\"><tr><td>bartMachine {bartMachine}</td><td style=\"text-align: right;\">R Documentation</td></tr></table>\n",
       "\n",
       "<h2>Build a BART Model</h2>\n",
       "\n",
       "<h3>Description</h3>\n",
       "\n",
       "<p>Builds a BART model for regression or classification.\n",
       "</p>\n",
       "\n",
       "\n",
       "<h3>Usage</h3>\n",
       "\n",
       "<pre>\n",
       "bartMachine(X = NULL, y = NULL, Xy = NULL, \n",
       "num_trees = 50, \n",
       "num_burn_in = 250, \n",
       "num_iterations_after_burn_in = 1000, \n",
       "alpha = 0.95, beta = 2, k = 2, q = 0.9, nu = 3, \n",
       "prob_rule_class = 0.5, \n",
       "mh_prob_steps = c(2.5, 2.5, 4)/9,\n",
       "debug_log = FALSE, \n",
       "run_in_sample = TRUE,  \n",
       "s_sq_y = \"mse\",\n",
       "sig_sq_est = NULL,\n",
       "cov_prior_vec = NULL, \n",
       "use_missing_data = FALSE, \n",
       "covariates_to_permute = NULL,\n",
       "num_rand_samps_in_library = 10000, \n",
       "use_missing_data_dummies_as_covars = FALSE, \n",
       "replace_missing_data_with_x_j_bar = FALSE,\n",
       "impute_missingness_with_rf_impute = FALSE,\n",
       "impute_missingness_with_x_j_bar_for_lm = TRUE,\n",
       "mem_cache_for_speed = TRUE,\n",
       "serialize = FALSE,\n",
       "seed = NULL,\n",
       "verbose = TRUE)\n",
       "\n",
       "build_bart_machine(X = NULL, y = NULL, Xy = NULL, \n",
       "num_trees = 50, \n",
       "num_burn_in = 250, \n",
       "num_iterations_after_burn_in = 1000, \n",
       "alpha = 0.95, beta = 2, k = 2, q = 0.9, nu = 3, \n",
       "prob_rule_class = 0.5, \n",
       "mh_prob_steps = c(2.5, 2.5, 4)/9,\n",
       "debug_log = FALSE, \n",
       "run_in_sample = TRUE,  \n",
       "s_sq_y = \"mse\",\n",
       "sig_sq_est = NULL,\n",
       "cov_prior_vec = NULL, \n",
       "use_missing_data = FALSE, \n",
       "covariates_to_permute = NULL,\n",
       "num_rand_samps_in_library = 10000, \n",
       "use_missing_data_dummies_as_covars = FALSE, \n",
       "replace_missing_data_with_x_j_bar = FALSE,\n",
       "impute_missingness_with_rf_impute = FALSE,\n",
       "impute_missingness_with_x_j_bar_for_lm = TRUE,\n",
       "mem_cache_for_speed = TRUE,\n",
       "serialize = FALSE,\n",
       "seed = NULL,\n",
       "verbose = TRUE)\n",
       "</pre>\n",
       "\n",
       "\n",
       "<h3>Arguments</h3>\n",
       "\n",
       "<table summary=\"R argblock\">\n",
       "<tr valign=\"top\"><td><code>X</code></td>\n",
       "<td>\n",
       "\n",
       "<p>Data frame of predictors. Factors are automatically converted to dummies interally. \n",
       "</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>y</code></td>\n",
       "<td>\n",
       "\n",
       "<p>Vector of response variable. If <code>y</code> is <code>numeric</code> or <code>integer</code>, a BART model for regression is built. If <code>y</code> is a factor with two levels, a BART model for classification is built.\n",
       "</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>Xy</code></td>\n",
       "<td>\n",
       "\n",
       "<p>A data frame of predictors and the response. The response column must be named &ldquo;y&rdquo;. \n",
       "</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>num_trees</code></td>\n",
       "<td>\n",
       "\n",
       "<p>The number of trees to be grown in the sum-of-trees model.\n",
       "</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>num_burn_in</code></td>\n",
       "<td>\n",
       "\n",
       "<p>Number of MCMC samples to be discarded as &ldquo;burn-in&rdquo;.\n",
       "</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>num_iterations_after_burn_in</code></td>\n",
       "<td>\n",
       "\n",
       "<p>Number of MCMC samples to draw from the posterior distribution of <i>\\hat{f}(x)</i>. \n",
       "</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>alpha</code></td>\n",
       "<td>\n",
       "\n",
       "<p>Base hyperparameter in tree prior for whether a node is nonterminal or not.\n",
       "</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>beta</code></td>\n",
       "<td>\n",
       "\n",
       "<p>Power hyperparameter in tree prior for whether a node is nonterminal or not.\n",
       "</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>k</code></td>\n",
       "<td>\n",
       "\n",
       "<p>For regression, <code>k</code> determines the prior probability that <i>E(Y|X)</i> is contained in the interval <i>(y_{min}, y_{max})</i>, based on a normal distribution. For example, when <i>k=2</i>, the prior probability is 95%. For classification, <code>k</code> determines the prior probability that <i>E(Y|X)</i> is between <i>(-3,3)</i>. Note that a larger value of <code>k</code> results in more shrinkage and a more conservative fit. \n",
       "</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>q</code></td>\n",
       "<td>\n",
       "\n",
       "<p>Quantile of the prior on the error variance at which the data-based estimate is placed. Note that the larger the value of <code>q</code>, the more aggressive the fit as you are placing more prior weight on values lower than the data-based estimate. Not used for classification.\n",
       "</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>nu</code></td>\n",
       "<td>\n",
       "\n",
       "<p>Degrees of freedom for the inverse <i>&chi;^2</i> prior. Not used for classification.\n",
       "</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>prob_rule_class</code></td>\n",
       "<td>\n",
       "\n",
       "<p>Threshold for classification. Any observation with a conditional probability greater than <code>prob_class_rule</code> is assigned the &ldquo;positive&rdquo; outcome. Note that the first level of the response is treated as the &ldquo;negative&rdquo; outcome and the second is treated as the &ldquo;positive&rdquo; outcome.  \n",
       "</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>mh_prob_steps</code></td>\n",
       "<td>\n",
       "\n",
       "<p>Vector of prior probabilities for proposing changes to the tree structures: (GROW, PRUNE, CHANGE)\n",
       "</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>debug_log</code></td>\n",
       "<td>\n",
       "\n",
       "<p>If TRUE, additional information about the model construction are printed to a file in the working directory.\n",
       "</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>run_in_sample</code></td>\n",
       "<td>\n",
       "\n",
       "<p>If TRUE, in-sample statistics such as <i>\\hat{f}(x)</i>, Pseudo-<i>R^2</i>, and RMSE are computed. Setting this to FALSE when not needed can decrease computation time. \n",
       "</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>s_sq_y</code></td>\n",
       "<td>\n",
       "\n",
       "<p>If &ldquo;mse&rdquo;, a data-based estimated of the error variance is computed as the MSE from ordinary least squares regression. If &ldquo;var&rdquo;., the data-based estimate is computed as the variance of the response. Not used in classification. \n",
       "</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>sig_sq_est</code></td>\n",
       "<td>\n",
       "\n",
       "<p>Pass in an estimate of the maximum sig_sq of the model. This is useful to cache somewhere and then pass in during cross-validation since the default method of estimation is a linear model. In large dimensions, linear model estimation is slow.\n",
       "</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>cov_prior_vec</code></td>\n",
       "<td>\n",
       "\n",
       "<p>Vector assigning relative weights to how often a particular variable should be proposed as a candidate for a split. The vector is internally normalized so that the weights sum to 1. Note that the length of this vector must equal the length of the design matrix after dummification and augmentation of indicators of missingness (if used). To see what the dummified matrix looks like, use <code>dummify_data</code>. See Bleich et al. (2013) for more details on when this feature is most appropriate. \n",
       "</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>use_missing_data</code></td>\n",
       "<td>\n",
       "\n",
       "<p>If TRUE, the missing data feature is used to automatically handle missing data without imputation. See Kapelner and Bleich (2013) for details. \n",
       "</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>covariates_to_permute</code></td>\n",
       "<td>\n",
       "\n",
       "<p>Private argument for <code>cov_importance_test</code>. Not needed by user. \n",
       "</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>num_rand_samps_in_library</code></td>\n",
       "<td>\n",
       "\n",
       "<p>Before building a BART model, samples from the Standard Normal and <i>&chi;^2(&nu;)</i> are drawn to be used in the MCMC steps. This parameter determines the number of samples to be taken.  \n",
       "</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>use_missing_data_dummies_as_covars</code></td>\n",
       "<td>\n",
       "\n",
       "<p>If TRUE, additional indicator variables for whether or not an observation in a particular column is missing are included. See Kapelner and Bleich (2013) for details.\n",
       "</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>replace_missing_data_with_x_j_bar</code></td>\n",
       "<td>\n",
       "\n",
       "<p>If TRUE ,missing entries in <code>X</code> are imputed with average value or modal category.\n",
       "</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>impute_missingness_with_rf_impute</code></td>\n",
       "<td>\n",
       "\n",
       "<p>If TRUE, missing entries are filled in using the rf.impute() function from the <code>randomForest</code> library. \n",
       "</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>impute_missingness_with_x_j_bar_for_lm</code></td>\n",
       "<td>\n",
       "\n",
       "<p>If TRUE, when computing the data-based estimate of <i>&sigma;^2</i>, missing entries are imputed with average value or modal category.\n",
       "</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>mem_cache_for_speed</code></td>\n",
       "<td>\n",
       "\n",
       "<p>Speed enhancement that caches the predictors and the split values that are available at each node for selecting new rules. If the number\n",
       "of predictors is large, the memory requirements become large. We recommend keeping this on (default) and turning it off if you experience out-of-memory errors.  \n",
       "</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>serialize</code></td>\n",
       "<td>\n",
       "\n",
       "<p>Setting this option to <code>TRUE</code> will allow serialization of bartMachine objects which allows for persistence between\n",
       "R sessions if the object is saved and reloaded. Note that serialized objects can take up a large amount of memory. \n",
       "Thus, the default is <code>FALSE</code>.  \n",
       "</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>seed</code></td>\n",
       "<td>\n",
       "\n",
       "<p>Optional: sets the seed in both R and Java. Default is <code>NULL</code> which does not set the seed in R nor Java.  \n",
       "</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>verbose</code></td>\n",
       "<td>\n",
       "\n",
       "<p>Prints information about progress of the algorithm to the screen. \n",
       "</p>\n",
       "</td></tr>\n",
       "</table>\n",
       "\n",
       "\n",
       "<h3>Value</h3>\n",
       "\n",
       "<p>Returns an object of class &ldquo;bartMachine&rdquo;. The &ldquo;bartMachine&rdquo; object contains a list of the following components:\n",
       "</p>\n",
       "<table summary=\"R valueblock\">\n",
       "<tr valign=\"top\"><td><code>java_bart_machine</code></td>\n",
       "<td>\n",
       "<p>A pointer to the BART Java object.</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>train_data_features</code></td>\n",
       "<td>\n",
       "<p>The names of the variables used in the training data.</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>training_data_features_with_missing_features.</code></td>\n",
       "<td>\n",
       "<p>The names of the variables used in the training data. If <code>use_missing_data_dummies_as_covars = TRUE</code>, this also includes dummies for any predictors that contain at least one missing entry (named &ldquo;M_&lt;feature&gt;&rdquo;).</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>y</code></td>\n",
       "<td>\n",
       "<p>The values of the response for the training data.</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>y_levels</code></td>\n",
       "<td>\n",
       "<p>The levels of the response (for classification only).</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>pred_type</code></td>\n",
       "<td>\n",
       "<p>Whether the model was build for regression of classification.</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>model_matrix_training_data</code></td>\n",
       "<td>\n",
       "<p>The training data with factors converted to dummies.</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>num_cores</code></td>\n",
       "<td>\n",
       "<p>The number of cores used to build the BART model.</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>sig_sq_est</code></td>\n",
       "<td>\n",
       "<p>The data-based estimate of <i>&sigma;^2</i> used to create the prior on the error variance for the BART model.</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>time_to_build</code></td>\n",
       "<td>\n",
       "<p>Total time to build the BART model.</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>y_hat_train</code></td>\n",
       "<td>\n",
       "<p>The posterior means of <i>\\hat{f}(x)</i> for each observation. Only returned if <code>run_in_sample = TRUE</code>.</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>residuals</code></td>\n",
       "<td>\n",
       "<p>The model residuals given by <code>y</code> - <code>y_hat_train</code>. Only returned if <code>run_in_sample = TRUE</code>.</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>L1_err_train</code></td>\n",
       "<td>\n",
       "<p>L1 error on the training set. Only returned if <code>run_in_sample = TRUE</code>.</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>L2_err_train</code></td>\n",
       "<td>\n",
       "<p>L2 error on the training set. Only returned if <code>run_in_sample = TRUE</code>.</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>PseudoRsq</code></td>\n",
       "<td>\n",
       "<p>Calculated as 1 - SSE / SST where SSE is the sum of square errors in the training data and SST is the sample variance of the response times <i>n-1</i>. Only returned if <code>run_in_sample = TRUE</code>.</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>rmse_train</code></td>\n",
       "<td>\n",
       "<p>Root mean square error on the training set. Only returned if <code>run_in_sample = TRUE</code>.</p>\n",
       "</td></tr>\n",
       "</table>\n",
       "<p>Additionally, the parameters passed to the function <code>bartMachine</code> are also components of the list. \n",
       "</p>\n",
       "\n",
       "\n",
       "<h3>Note</h3>\n",
       "\n",
       "<p>This function is parallelized by the number of cores set by <code>set_bart_machine_num_cores</code>. Each core will create an \n",
       "independent MCMC chain of size <br />\n",
       "<code>num_burn_in</code> <i>+</i> <code>num_iterations_after_burn_in / bart_machine_num_cores</code>.\n",
       "</p>\n",
       "\n",
       "\n",
       "<h3>Author(s)</h3>\n",
       "\n",
       "<p>Adam Kapelner and Justin Bleich\n",
       "</p>\n",
       "\n",
       "\n",
       "<h3>References</h3>\n",
       "\n",
       "<p>HA Chipman, EI George, and RE McCulloch. BART: Bayesian Additive Regressive Trees.\n",
       "The Annals of Applied Statistics, 4(1): 266&ndash;298, 2010.\n",
       "</p>\n",
       "<p>A Kapelner and J Bleich. Prediction with Missing Data via Bayesian Additive Regression\n",
       "Trees. ArXiv e-prints, 2013.\n",
       "</p>\n",
       "<p>J Bleich, A Kapelner, ST Jensen, and EI George. Variable Selection Inference for Bayesian\n",
       "Additive Regression Trees. ArXiv e-prints, 2013.\n",
       "</p>\n",
       "\n",
       "\n",
       "<h3>See Also</h3>\n",
       "\n",
       "<p><code>bartMachineCV</code>\n",
       "</p>\n",
       "\n",
       "\n",
       "<h3>Examples</h3>\n",
       "\n",
       "<pre>\n",
       "##regression example\n",
       "\n",
       "##generate Friedman data\n",
       "set.seed(11)\n",
       "n  = 200 \n",
       "p = 5\n",
       "X = data.frame(matrix(runif(n * p), ncol = p))\n",
       "y = 10 * sin(pi* X[ ,1] * X[,2]) +20 * (X[,3] -.5)^2 + 10 * X[ ,4] + 5 * X[,5] + rnorm(n)\n",
       "\n",
       "##build BART regression model\n",
       "bart_machine = bartMachine(X, y)\n",
       "summary(bart_machine)\n",
       "\n",
       "## Not run: \n",
       "##Build another BART regression model\n",
       "bart_machine = bartMachine(X,y, num_trees = 200, num_burn_in = 500,\n",
       "num_iterations_after_burn_in = 1000)\n",
       "\n",
       "##Classification example\n",
       "\n",
       "#get data and only use 2 factors\n",
       "data(iris)\n",
       "iris2 = iris[51:150,]\n",
       "iris2$Species = factor(iris2$Species)\n",
       "\n",
       "#build BART classification model\n",
       "bart_machine = build_bart_machine(iris2[ ,1:4], iris2$Species)\n",
       "\n",
       "##get estimated probabilities\n",
       "phat = bart_machine$p_hat_train\n",
       "##look at in-sample confusion matrix\n",
       "bart_machine$confusion_matrix\n",
       "\n",
       "## End(Not run)\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "</pre>\n",
       "\n",
       "<hr /><div style=\"text-align: center;\">[Package <em>bartMachine</em> version 1.2.1 ]</div>"
      ],
      "text/latex": [
       "\\inputencoding{utf8}\n",
       "\\HeaderA{bartMachine}{Build a BART Model}{bartMachine}\n",
       "\\aliasA{build\\_bart\\_machine}{bartMachine}{build.Rul.bart.Rul.machine}\n",
       "\\keyword{\\textbackslash{}textasciitilde{}kwd1}{bartMachine}\n",
       "\\keyword{\\textbackslash{}textasciitilde{}kwd2}{bartMachine}\n",
       "%\n",
       "\\begin{Description}\\relax\n",
       "Builds a BART model for regression or classification.\n",
       "\\end{Description}\n",
       "%\n",
       "\\begin{Usage}\n",
       "\\begin{verbatim}\n",
       "bartMachine(X = NULL, y = NULL, Xy = NULL, \n",
       "num_trees = 50, \n",
       "num_burn_in = 250, \n",
       "num_iterations_after_burn_in = 1000, \n",
       "alpha = 0.95, beta = 2, k = 2, q = 0.9, nu = 3, \n",
       "prob_rule_class = 0.5, \n",
       "mh_prob_steps = c(2.5, 2.5, 4)/9,\n",
       "debug_log = FALSE, \n",
       "run_in_sample = TRUE,  \n",
       "s_sq_y = \"mse\",\n",
       "sig_sq_est = NULL,\n",
       "cov_prior_vec = NULL, \n",
       "use_missing_data = FALSE, \n",
       "covariates_to_permute = NULL,\n",
       "num_rand_samps_in_library = 10000, \n",
       "use_missing_data_dummies_as_covars = FALSE, \n",
       "replace_missing_data_with_x_j_bar = FALSE,\n",
       "impute_missingness_with_rf_impute = FALSE,\n",
       "impute_missingness_with_x_j_bar_for_lm = TRUE,\n",
       "mem_cache_for_speed = TRUE,\n",
       "serialize = FALSE,\n",
       "seed = NULL,\n",
       "verbose = TRUE)\n",
       "\n",
       "build_bart_machine(X = NULL, y = NULL, Xy = NULL, \n",
       "num_trees = 50, \n",
       "num_burn_in = 250, \n",
       "num_iterations_after_burn_in = 1000, \n",
       "alpha = 0.95, beta = 2, k = 2, q = 0.9, nu = 3, \n",
       "prob_rule_class = 0.5, \n",
       "mh_prob_steps = c(2.5, 2.5, 4)/9,\n",
       "debug_log = FALSE, \n",
       "run_in_sample = TRUE,  \n",
       "s_sq_y = \"mse\",\n",
       "sig_sq_est = NULL,\n",
       "cov_prior_vec = NULL, \n",
       "use_missing_data = FALSE, \n",
       "covariates_to_permute = NULL,\n",
       "num_rand_samps_in_library = 10000, \n",
       "use_missing_data_dummies_as_covars = FALSE, \n",
       "replace_missing_data_with_x_j_bar = FALSE,\n",
       "impute_missingness_with_rf_impute = FALSE,\n",
       "impute_missingness_with_x_j_bar_for_lm = TRUE,\n",
       "mem_cache_for_speed = TRUE,\n",
       "serialize = FALSE,\n",
       "seed = NULL,\n",
       "verbose = TRUE)\n",
       "\\end{verbatim}\n",
       "\\end{Usage}\n",
       "%\n",
       "\\begin{Arguments}\n",
       "\\begin{ldescription}\n",
       "\\item[\\code{X}] \n",
       "Data frame of predictors. Factors are automatically converted to dummies interally. \n",
       "\n",
       "\\item[\\code{y}] \n",
       "Vector of response variable. If \\code{y} is \\code{numeric} or \\code{integer}, a BART model for regression is built. If \\code{y} is a factor with two levels, a BART model for classification is built.\n",
       "\n",
       "\\item[\\code{Xy}] \n",
       "A data frame of predictors and the response. The response column must be named ``y''. \n",
       "\n",
       "\\item[\\code{num\\_trees}] \n",
       "The number of trees to be grown in the sum-of-trees model.\n",
       "\n",
       "\\item[\\code{num\\_burn\\_in}] \n",
       "Number of MCMC samples to be discarded as ``burn-in''.\n",
       "\n",
       "\\item[\\code{num\\_iterations\\_after\\_burn\\_in}] \n",
       "Number of MCMC samples to draw from the posterior distribution of \\eqn{\\hat{f}(x)}{}. \n",
       "\n",
       "\\item[\\code{alpha}] \n",
       "Base hyperparameter in tree prior for whether a node is nonterminal or not.\n",
       "\n",
       "\\item[\\code{beta}] \n",
       "Power hyperparameter in tree prior for whether a node is nonterminal or not.\n",
       "\n",
       "\\item[\\code{k}] \n",
       "For regression, \\code{k} determines the prior probability that \\eqn{E(Y|X)}{} is contained in the interval \\eqn{(y_{min}, y_{max})}{}, based on a normal distribution. For example, when \\eqn{k=2}{}, the prior probability is 95\\%. For classification, \\code{k} determines the prior probability that \\eqn{E(Y|X)}{} is between \\eqn{(-3,3)}{}. Note that a larger value of \\code{k} results in more shrinkage and a more conservative fit. \n",
       "\n",
       "\\item[\\code{q}] \n",
       "Quantile of the prior on the error variance at which the data-based estimate is placed. Note that the larger the value of \\code{q}, the more aggressive the fit as you are placing more prior weight on values lower than the data-based estimate. Not used for classification.\n",
       "\n",
       "\\item[\\code{nu}] \n",
       "Degrees of freedom for the inverse \\eqn{\\chi^2}{} prior. Not used for classification.\n",
       "\n",
       "\\item[\\code{prob\\_rule\\_class}] \n",
       "Threshold for classification. Any observation with a conditional probability greater than \\code{prob\\_class\\_rule} is assigned the ``positive'' outcome. Note that the first level of the response is treated as the ``negative'' outcome and the second is treated as the ``positive'' outcome.  \n",
       "\n",
       "\\item[\\code{mh\\_prob\\_steps}] \n",
       "Vector of prior probabilities for proposing changes to the tree structures: (GROW, PRUNE, CHANGE)\n",
       "\n",
       "\\item[\\code{debug\\_log}] \n",
       "If TRUE, additional information about the model construction are printed to a file in the working directory.\n",
       "\n",
       "\\item[\\code{run\\_in\\_sample}] \n",
       "If TRUE, in-sample statistics such as \\eqn{\\hat{f}(x)}{}, Pseudo-\\eqn{R^2}{}, and RMSE are computed. Setting this to FALSE when not needed can decrease computation time. \n",
       "\n",
       "\\item[\\code{s\\_sq\\_y}] \n",
       "If ``mse'', a data-based estimated of the error variance is computed as the MSE from ordinary least squares regression. If ``var''., the data-based estimate is computed as the variance of the response. Not used in classification. \n",
       "\n",
       "\\item[\\code{sig\\_sq\\_est}] \n",
       "Pass in an estimate of the maximum sig\\_sq of the model. This is useful to cache somewhere and then pass in during cross-validation since the default method of estimation is a linear model. In large dimensions, linear model estimation is slow.\n",
       "\n",
       "\\item[\\code{cov\\_prior\\_vec}] \n",
       "Vector assigning relative weights to how often a particular variable should be proposed as a candidate for a split. The vector is internally normalized so that the weights sum to 1. Note that the length of this vector must equal the length of the design matrix after dummification and augmentation of indicators of missingness (if used). To see what the dummified matrix looks like, use \\code{\\LinkA{dummify\\_data}{dummify.Rul.data}}. See Bleich et al. (2013) for more details on when this feature is most appropriate. \n",
       "\n",
       "\\item[\\code{use\\_missing\\_data}] \n",
       "If TRUE, the missing data feature is used to automatically handle missing data without imputation. See Kapelner and Bleich (2013) for details. \n",
       "\n",
       "\\item[\\code{covariates\\_to\\_permute}] \n",
       "Private argument for \\code{\\LinkA{cov\\_importance\\_test}{cov.Rul.importance.Rul.test}}. Not needed by user. \n",
       "\n",
       "\\item[\\code{num\\_rand\\_samps\\_in\\_library}] \n",
       "Before building a BART model, samples from the Standard Normal and \\eqn{\\chi^2(\\nu)}{} are drawn to be used in the MCMC steps. This parameter determines the number of samples to be taken.  \n",
       "\n",
       "\\item[\\code{use\\_missing\\_data\\_dummies\\_as\\_covars}] \n",
       "If TRUE, additional indicator variables for whether or not an observation in a particular column is missing are included. See Kapelner and Bleich (2013) for details.\n",
       "\n",
       "\\item[\\code{replace\\_missing\\_data\\_with\\_x\\_j\\_bar}] \n",
       "If TRUE ,missing entries in \\code{X} are imputed with average value or modal category.\n",
       "\n",
       "\n",
       "\\item[\\code{impute\\_missingness\\_with\\_rf\\_impute}] \n",
       "If TRUE, missing entries are filled in using the rf.impute() function from the \\code{randomForest} library. \n",
       "\n",
       "\\item[\\code{impute\\_missingness\\_with\\_x\\_j\\_bar\\_for\\_lm}] \n",
       "If TRUE, when computing the data-based estimate of \\eqn{\\sigma^2}{}, missing entries are imputed with average value or modal category.\n",
       "\n",
       "\\item[\\code{mem\\_cache\\_for\\_speed}] \n",
       "Speed enhancement that caches the predictors and the split values that are available at each node for selecting new rules. If the number\n",
       "of predictors is large, the memory requirements become large. We recommend keeping this on (default) and turning it off if you experience out-of-memory errors.  \n",
       "\n",
       "\\item[\\code{serialize}] \n",
       "Setting this option to \\code{TRUE} will allow serialization of bartMachine objects which allows for persistence between\n",
       "R sessions if the object is saved and reloaded. Note that serialized objects can take up a large amount of memory. \n",
       "Thus, the default is \\code{FALSE}.  \n",
       "\n",
       "\\item[\\code{seed}] \n",
       "Optional: sets the seed in both R and Java. Default is \\code{NULL} which does not set the seed in R nor Java.  \n",
       "\n",
       "\\item[\\code{verbose}] \n",
       "Prints information about progress of the algorithm to the screen. \n",
       "\n",
       "\\end{ldescription}\n",
       "\\end{Arguments}\n",
       "%\n",
       "\\begin{Value}\n",
       "Returns an object of class ``bartMachine''. The ``bartMachine'' object contains a list of the following components:\n",
       "\n",
       "\\begin{ldescription}\n",
       "\\item[\\code{java\\_bart\\_machine}] A pointer to the BART Java object.\n",
       "\\item[\\code{train\\_data\\_features}] The names of the variables used in the training data.\n",
       "\\item[\\code{training\\_data\\_features\\_with\\_missing\\_features.}] The names of the variables used in the training data. If \\code{use\\_missing\\_data\\_dummies\\_as\\_covars = TRUE}, this also includes dummies for any predictors that contain at least one missing entry (named ``M\\_<feature>'').\n",
       "\\item[\\code{y}] The values of the response for the training data.\n",
       "\\item[\\code{y\\_levels}] The levels of the response (for classification only).\n",
       "\\item[\\code{pred\\_type}] Whether the model was build for regression of classification.\n",
       "\\item[\\code{model\\_matrix\\_training\\_data}] The training data with factors converted to dummies.\n",
       "\\item[\\code{num\\_cores}] The number of cores used to build the BART model.\n",
       "\\item[\\code{sig\\_sq\\_est}] The data-based estimate of \\eqn{\\sigma^2}{} used to create the prior on the error variance for the BART model.\n",
       "\\item[\\code{time\\_to\\_build}] Total time to build the BART model.\n",
       "\\item[\\code{y\\_hat\\_train}] The posterior means of \\eqn{\\hat{f}(x)}{} for each observation. Only returned if \\code{run\\_in\\_sample = TRUE}.\n",
       "\\item[\\code{residuals}] The model residuals given by \\code{y} - \\code{y\\_hat\\_train}. Only returned if \\code{run\\_in\\_sample = TRUE}.\n",
       "\\item[\\code{L1\\_err\\_train}] L1 error on the training set. Only returned if \\code{run\\_in\\_sample = TRUE}.\n",
       "\\item[\\code{L2\\_err\\_train}] L2 error on the training set. Only returned if \\code{run\\_in\\_sample = TRUE}.\n",
       "\\item[\\code{PseudoRsq}] Calculated as 1 - SSE / SST where SSE is the sum of square errors in the training data and SST is the sample variance of the response times \\eqn{n-1}{}. Only returned if \\code{run\\_in\\_sample = TRUE}.\n",
       "\\item[\\code{rmse\\_train}] Root mean square error on the training set. Only returned if \\code{run\\_in\\_sample = TRUE}.\n",
       "\n",
       "\\end{ldescription}\n",
       "Additionally, the parameters passed to the function \\code{bartMachine} are also components of the list. \n",
       "\\end{Value}\n",
       "%\n",
       "\\begin{Note}\\relax\n",
       "This function is parallelized by the number of cores set by \\code{\\LinkA{set\\_bart\\_machine\\_num\\_cores}{set.Rul.bart.Rul.machine.Rul.num.Rul.cores}}. Each core will create an \n",
       "independent MCMC chain of size \\\\{}\n",
       "\\code{num\\_burn\\_in} \\eqn{+}{} \\code{num\\_iterations\\_after\\_burn\\_in / bart\\_machine\\_num\\_cores}.\n",
       "\\end{Note}\n",
       "%\n",
       "\\begin{Author}\\relax\n",
       "Adam Kapelner and Justin Bleich\n",
       "\\end{Author}\n",
       "%\n",
       "\\begin{References}\\relax\n",
       "HA Chipman, EI George, and RE McCulloch. BART: Bayesian Additive Regressive Trees.\n",
       "The Annals of Applied Statistics, 4(1): 266--298, 2010.\n",
       "\n",
       "A Kapelner and J Bleich. Prediction with Missing Data via Bayesian Additive Regression\n",
       "Trees. ArXiv e-prints, 2013.\n",
       "\n",
       "J Bleich, A Kapelner, ST Jensen, and EI George. Variable Selection Inference for Bayesian\n",
       "Additive Regression Trees. ArXiv e-prints, 2013.\n",
       "\\end{References}\n",
       "%\n",
       "\\begin{SeeAlso}\\relax\n",
       "\\code{\\LinkA{bartMachineCV}{bartMachineCV}}\n",
       "\\end{SeeAlso}\n",
       "%\n",
       "\\begin{Examples}\n",
       "\\begin{ExampleCode}\n",
       "##regression example\n",
       "\n",
       "##generate Friedman data\n",
       "set.seed(11)\n",
       "n  = 200 \n",
       "p = 5\n",
       "X = data.frame(matrix(runif(n * p), ncol = p))\n",
       "y = 10 * sin(pi* X[ ,1] * X[,2]) +20 * (X[,3] -.5)^2 + 10 * X[ ,4] + 5 * X[,5] + rnorm(n)\n",
       "\n",
       "##build BART regression model\n",
       "bart_machine = bartMachine(X, y)\n",
       "summary(bart_machine)\n",
       "\n",
       "## Not run: \n",
       "##Build another BART regression model\n",
       "bart_machine = bartMachine(X,y, num_trees = 200, num_burn_in = 500,\n",
       "num_iterations_after_burn_in = 1000)\n",
       "\n",
       "##Classification example\n",
       "\n",
       "#get data and only use 2 factors\n",
       "data(iris)\n",
       "iris2 = iris[51:150,]\n",
       "iris2$Species = factor(iris2$Species)\n",
       "\n",
       "#build BART classification model\n",
       "bart_machine = build_bart_machine(iris2[ ,1:4], iris2$Species)\n",
       "\n",
       "##get estimated probabilities\n",
       "phat = bart_machine$p_hat_train\n",
       "##look at in-sample confusion matrix\n",
       "bart_machine$confusion_matrix\n",
       "\n",
       "## End(Not run)\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\\end{ExampleCode}\n",
       "\\end{Examples}"
      ],
      "text/plain": [
       "bartMachine            package:bartMachine             R Documentation\n",
       "\n",
       "_\bB_\bu_\bi_\bl_\bd _\ba _\bB_\bA_\bR_\bT _\bM_\bo_\bd_\be_\bl\n",
       "\n",
       "_\bD_\be_\bs_\bc_\br_\bi_\bp_\bt_\bi_\bo_\bn:\n",
       "\n",
       "     Builds a BART model for regression or classification.\n",
       "\n",
       "_\bU_\bs_\ba_\bg_\be:\n",
       "\n",
       "     bartMachine(X = NULL, y = NULL, Xy = NULL, \n",
       "     num_trees = 50, \n",
       "     num_burn_in = 250, \n",
       "     num_iterations_after_burn_in = 1000, \n",
       "     alpha = 0.95, beta = 2, k = 2, q = 0.9, nu = 3, \n",
       "     prob_rule_class = 0.5, \n",
       "     mh_prob_steps = c(2.5, 2.5, 4)/9,\n",
       "     debug_log = FALSE, \n",
       "     run_in_sample = TRUE,  \n",
       "     s_sq_y = \"mse\",\n",
       "     sig_sq_est = NULL,\n",
       "     cov_prior_vec = NULL, \n",
       "     use_missing_data = FALSE, \n",
       "     covariates_to_permute = NULL,\n",
       "     num_rand_samps_in_library = 10000, \n",
       "     use_missing_data_dummies_as_covars = FALSE, \n",
       "     replace_missing_data_with_x_j_bar = FALSE,\n",
       "     impute_missingness_with_rf_impute = FALSE,\n",
       "     impute_missingness_with_x_j_bar_for_lm = TRUE,\n",
       "     mem_cache_for_speed = TRUE,\n",
       "     serialize = FALSE,\n",
       "     seed = NULL,\n",
       "     verbose = TRUE)\n",
       "     \n",
       "     build_bart_machine(X = NULL, y = NULL, Xy = NULL, \n",
       "     num_trees = 50, \n",
       "     num_burn_in = 250, \n",
       "     num_iterations_after_burn_in = 1000, \n",
       "     alpha = 0.95, beta = 2, k = 2, q = 0.9, nu = 3, \n",
       "     prob_rule_class = 0.5, \n",
       "     mh_prob_steps = c(2.5, 2.5, 4)/9,\n",
       "     debug_log = FALSE, \n",
       "     run_in_sample = TRUE,  \n",
       "     s_sq_y = \"mse\",\n",
       "     sig_sq_est = NULL,\n",
       "     cov_prior_vec = NULL, \n",
       "     use_missing_data = FALSE, \n",
       "     covariates_to_permute = NULL,\n",
       "     num_rand_samps_in_library = 10000, \n",
       "     use_missing_data_dummies_as_covars = FALSE, \n",
       "     replace_missing_data_with_x_j_bar = FALSE,\n",
       "     impute_missingness_with_rf_impute = FALSE,\n",
       "     impute_missingness_with_x_j_bar_for_lm = TRUE,\n",
       "     mem_cache_for_speed = TRUE,\n",
       "     serialize = FALSE,\n",
       "     seed = NULL,\n",
       "     verbose = TRUE)\n",
       "     \n",
       "_\bA_\br_\bg_\bu_\bm_\be_\bn_\bt_\bs:\n",
       "\n",
       "       X: Data frame of predictors. Factors are automatically converted\n",
       "          to dummies interally.\n",
       "\n",
       "       y: Vector of response variable. If ‘y’ is ‘numeric’ or\n",
       "          ‘integer’, a BART model for regression is built. If ‘y’ is a\n",
       "          factor with two levels, a BART model for classification is\n",
       "          built.\n",
       "\n",
       "      Xy: A data frame of predictors and the response. The response\n",
       "          column must be named ``y''.\n",
       "\n",
       "num_trees: The number of trees to be grown in the sum-of-trees model.\n",
       "\n",
       "num_burn_in: Number of MCMC samples to be discarded as ``burn-in''.\n",
       "\n",
       "num_iterations_after_burn_in: Number of MCMC samples to draw from the\n",
       "          posterior distribution of \\hat{f}(x).\n",
       "\n",
       "   alpha: Base hyperparameter in tree prior for whether a node is\n",
       "          nonterminal or not.\n",
       "\n",
       "    beta: Power hyperparameter in tree prior for whether a node is\n",
       "          nonterminal or not.\n",
       "\n",
       "       k: For regression, ‘k’ determines the prior probability that\n",
       "          E(Y|X) is contained in the interval (y_{min}, y_{max}), based\n",
       "          on a normal distribution. For example, when k=2, the prior\n",
       "          probability is 95%. For classification, ‘k’ determines the\n",
       "          prior probability that E(Y|X) is between (-3,3). Note that a\n",
       "          larger value of ‘k’ results in more shrinkage and a more\n",
       "          conservative fit.\n",
       "\n",
       "       q: Quantile of the prior on the error variance at which the\n",
       "          data-based estimate is placed. Note that the larger the value\n",
       "          of ‘q’, the more aggressive the fit as you are placing more\n",
       "          prior weight on values lower than the data-based estimate.\n",
       "          Not used for classification.\n",
       "\n",
       "      nu: Degrees of freedom for the inverse chi^2 prior. Not used for\n",
       "          classification.\n",
       "\n",
       "prob_rule_class: Threshold for classification. Any observation with a\n",
       "          conditional probability greater than ‘prob_class_rule’ is\n",
       "          assigned the ``positive'' outcome. Note that the first level\n",
       "          of the response is treated as the ``negative'' outcome and\n",
       "          the second is treated as the ``positive'' outcome.\n",
       "\n",
       "mh_prob_steps: Vector of prior probabilities for proposing changes to\n",
       "          the tree structures: (GROW, PRUNE, CHANGE)\n",
       "\n",
       "debug_log: If TRUE, additional information about the model construction\n",
       "          are printed to a file in the working directory.\n",
       "\n",
       "run_in_sample: If TRUE, in-sample statistics such as \\hat{f}(x),\n",
       "          Pseudo-R^2, and RMSE are computed. Setting this to FALSE when\n",
       "          not needed can decrease computation time.\n",
       "\n",
       "  s_sq_y: If ``mse'', a data-based estimated of the error variance is\n",
       "          computed as the MSE from ordinary least squares regression.\n",
       "          If ``var''., the data-based estimate is computed as the\n",
       "          variance of the response. Not used in classification.\n",
       "\n",
       "sig_sq_est: Pass in an estimate of the maximum sig_sq of the model.\n",
       "          This is useful to cache somewhere and then pass in during\n",
       "          cross-validation since the default method of estimation is a\n",
       "          linear model. In large dimensions, linear model estimation is\n",
       "          slow.\n",
       "\n",
       "cov_prior_vec: Vector assigning relative weights to how often a\n",
       "          particular variable should be proposed as a candidate for a\n",
       "          split. The vector is internally normalized so that the\n",
       "          weights sum to 1. Note that the length of this vector must\n",
       "          equal the length of the design matrix after dummification and\n",
       "          augmentation of indicators of missingness (if used). To see\n",
       "          what the dummified matrix looks like, use ‘dummify_data’. See\n",
       "          Bleich et al. (2013) for more details on when this feature is\n",
       "          most appropriate.\n",
       "\n",
       "use_missing_data: If TRUE, the missing data feature is used to\n",
       "          automatically handle missing data without imputation. See\n",
       "          Kapelner and Bleich (2013) for details.\n",
       "\n",
       "covariates_to_permute: Private argument for ‘cov_importance_test’. Not\n",
       "          needed by user.\n",
       "\n",
       "num_rand_samps_in_library: Before building a BART model, samples from\n",
       "          the Standard Normal and chi^2(nu) are drawn to be used in the\n",
       "          MCMC steps. This parameter determines the number of samples\n",
       "          to be taken.\n",
       "\n",
       "use_missing_data_dummies_as_covars: If TRUE, additional indicator\n",
       "          variables for whether or not an observation in a particular\n",
       "          column is missing are included. See Kapelner and Bleich\n",
       "          (2013) for details.\n",
       "\n",
       "replace_missing_data_with_x_j_bar: If TRUE ,missing entries in ‘X’ are\n",
       "          imputed with average value or modal category.\n",
       "\n",
       "impute_missingness_with_rf_impute: If TRUE, missing entries are filled\n",
       "          in using the rf.impute() function from the ‘randomForest’\n",
       "          library.\n",
       "\n",
       "impute_missingness_with_x_j_bar_for_lm: If TRUE, when computing the\n",
       "          data-based estimate of sigma^2, missing entries are imputed\n",
       "          with average value or modal category.\n",
       "\n",
       "mem_cache_for_speed: Speed enhancement that caches the predictors and\n",
       "          the split values that are available at each node for\n",
       "          selecting new rules. If the number of predictors is large,\n",
       "          the memory requirements become large. We recommend keeping\n",
       "          this on (default) and turning it off if you experience\n",
       "          out-of-memory errors.\n",
       "\n",
       "serialize: Setting this option to ‘TRUE’ will allow serialization of\n",
       "          bartMachine objects which allows for persistence between R\n",
       "          sessions if the object is saved and reloaded. Note that\n",
       "          serialized objects can take up a large amount of memory.\n",
       "          Thus, the default is ‘FALSE’.\n",
       "\n",
       "    seed: Optional: sets the seed in both R and Java. Default is ‘NULL’\n",
       "          which does not set the seed in R nor Java.\n",
       "\n",
       " verbose: Prints information about progress of the algorithm to the\n",
       "          screen.\n",
       "\n",
       "_\bV_\ba_\bl_\bu_\be:\n",
       "\n",
       "     Returns an object of class ``bartMachine''. The ``bartMachine''\n",
       "     object contains a list of the following components:\n",
       "\n",
       "java_bart_machine: A pointer to the BART Java object.\n",
       "\n",
       "train_data_features: The names of the variables used in the training\n",
       "          data.\n",
       "\n",
       "training_data_features_with_missing_features.: The names of the\n",
       "          variables used in the training data. If\n",
       "          ‘use_missing_data_dummies_as_covars = TRUE’, this also\n",
       "          includes dummies for any predictors that contain at least one\n",
       "          missing entry (named ``M_<feature>'').\n",
       "\n",
       "       y: The values of the response for the training data.\n",
       "\n",
       "y_levels: The levels of the response (for classification only).\n",
       "\n",
       "pred_type: Whether the model was build for regression of\n",
       "          classification.\n",
       "\n",
       "model_matrix_training_data: The training data with factors converted to\n",
       "          dummies.\n",
       "\n",
       "num_cores: The number of cores used to build the BART model.\n",
       "\n",
       "sig_sq_est: The data-based estimate of sigma^2 used to create the prior\n",
       "          on the error variance for the BART model.\n",
       "\n",
       "time_to_build: Total time to build the BART model.\n",
       "\n",
       "y_hat_train: The posterior means of \\hat{f}(x) for each observation.\n",
       "          Only returned if ‘run_in_sample = TRUE’.\n",
       "\n",
       "residuals: The model residuals given by ‘y’ - ‘y_hat_train’. Only\n",
       "          returned if ‘run_in_sample = TRUE’.\n",
       "\n",
       "L1_err_train: L1 error on the training set. Only returned if\n",
       "          ‘run_in_sample = TRUE’.\n",
       "\n",
       "L2_err_train: L2 error on the training set. Only returned if\n",
       "          ‘run_in_sample = TRUE’.\n",
       "\n",
       "PseudoRsq: Calculated as 1 - SSE / SST where SSE is the sum of square\n",
       "          errors in the training data and SST is the sample variance of\n",
       "          the response times n-1. Only returned if ‘run_in_sample =\n",
       "          TRUE’.\n",
       "\n",
       "rmse_train: Root mean square error on the training set. Only returned\n",
       "          if ‘run_in_sample = TRUE’.\n",
       "     Additionally, the parameters passed to the function ‘bartMachine’\n",
       "     are also components of the list.\n",
       "\n",
       "_\bN_\bo_\bt_\be:\n",
       "\n",
       "     This function is parallelized by the number of cores set by\n",
       "     ‘set_bart_machine_num_cores’. Each core will create an independent\n",
       "     MCMC chain of size\n",
       "     ‘num_burn_in’ + ‘num_iterations_after_burn_in /\n",
       "     bart_machine_num_cores’.\n",
       "\n",
       "_\bA_\bu_\bt_\bh_\bo_\br(_\bs):\n",
       "\n",
       "     Adam Kapelner and Justin Bleich\n",
       "\n",
       "_\bR_\be_\bf_\be_\br_\be_\bn_\bc_\be_\bs:\n",
       "\n",
       "     HA Chipman, EI George, and RE McCulloch. BART: Bayesian Additive\n",
       "     Regressive Trees. The Annals of Applied Statistics, 4(1): 266-298,\n",
       "     2010.\n",
       "\n",
       "     A Kapelner and J Bleich. Prediction with Missing Data via Bayesian\n",
       "     Additive Regression Trees. ArXiv e-prints, 2013.\n",
       "\n",
       "     J Bleich, A Kapelner, ST Jensen, and EI George. Variable Selection\n",
       "     Inference for Bayesian Additive Regression Trees. ArXiv e-prints,\n",
       "     2013.\n",
       "\n",
       "_\bS_\be_\be _\bA_\bl_\bs_\bo:\n",
       "\n",
       "     ‘bartMachineCV’\n",
       "\n",
       "_\bE_\bx_\ba_\bm_\bp_\bl_\be_\bs:\n",
       "\n",
       "     ##regression example\n",
       "     \n",
       "     ##generate Friedman data\n",
       "     set.seed(11)\n",
       "     n  = 200 \n",
       "     p = 5\n",
       "     X = data.frame(matrix(runif(n * p), ncol = p))\n",
       "     y = 10 * sin(pi* X[ ,1] * X[,2]) +20 * (X[,3] -.5)^2 + 10 * X[ ,4] + 5 * X[,5] + rnorm(n)\n",
       "     \n",
       "     ##build BART regression model\n",
       "     bart_machine = bartMachine(X, y)\n",
       "     summary(bart_machine)\n",
       "     \n",
       "     ## Not run:\n",
       "     \n",
       "     ##Build another BART regression model\n",
       "     bart_machine = bartMachine(X,y, num_trees = 200, num_burn_in = 500,\n",
       "     num_iterations_after_burn_in = 1000)\n",
       "     \n",
       "     ##Classification example\n",
       "     \n",
       "     #get data and only use 2 factors\n",
       "     data(iris)\n",
       "     iris2 = iris[51:150,]\n",
       "     iris2$Species = factor(iris2$Species)\n",
       "     \n",
       "     #build BART classification model\n",
       "     bart_machine = build_bart_machine(iris2[ ,1:4], iris2$Species)\n",
       "     \n",
       "     ##get estimated probabilities\n",
       "     phat = bart_machine$p_hat_train\n",
       "     ##look at in-sample confusion matrix\n",
       "     bart_machine$confusion_matrix\n",
       "     ## End(Not run)\n",
       "     "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "?bartMachine\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bartMachine initializing with 50 trees...\n",
      "bartMachine vars checked...\n",
      "bartMachine java init...\n",
      "bartMachine factors created...\n",
      "bartMachine before preprocess...\n",
      "bartMachine after preprocess... 226 total features...\n",
      "bartMachine sigsq estimated...\n",
      "bartMachine training data finalized...\n",
      "Now building bartMachine for classification ...Covariate importance prior ON. Missing data feature ON. \n",
      "evaluating in sample data...done\n"
     ]
    }
   ],
   "source": [
    "fits[['status_group.functional']] <- bartMachine(training[,predictors],\n",
    "                                                 factor(training[,'status_group.functional']),\n",
    "                                                 use_missing_data = TRUE, mem_cache_for_speed = FALSE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bartMachine initializing with 50 trees...\n",
      "bartMachine vars checked...\n",
      "bartMachine java init...\n",
      "bartMachine factors created...\n",
      "bartMachine before preprocess...\n",
      "bartMachine after preprocess... 226 total features...\n",
      "bartMachine sigsq estimated...\n",
      "bartMachine training data finalized...\n",
      "Now building bartMachine for classification ...Covariate importance prior ON. Missing data feature ON. \n",
      "evaluating in sample data...done\n"
     ]
    }
   ],
   "source": [
    "fits[['status_group.non.functional']] <- bartMachine(training[,predictors],\n",
    "                                                     factor(training[,'status_group.non.functional']),\n",
    "                                                     use_missing_data = TRUE, mem_cache_for_speed = FALSE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bartMachine initializing with 50 trees...\n",
      "bartMachine vars checked...\n",
      "bartMachine java init...\n",
      "bartMachine factors created...\n",
      "bartMachine before preprocess...\n",
      "bartMachine after preprocess... 226 total features...\n",
      "bartMachine sigsq estimated...\n",
      "bartMachine training data finalized...\n",
      "Now building bartMachine for classification ...Covariate importance prior ON. Missing data feature ON. \n",
      "evaluating in sample data...done\n"
     ]
    }
   ],
   "source": [
    "fits[['status_group.functional.needs.repair']] <- bartMachine(training[,predictors],\n",
    "                                                              factor(training[,'status_group.functional.needs.repair']),\n",
    "                                                              use_missing_data = TRUE, mem_cache_for_speed = FALSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bartMachine initializing with 50 trees...\n",
      "bartMachine vars checked...\n",
      "bartMachine java init...\n",
      "bartMachine factors created...\n",
      "bartMachine before preprocess...\n",
      "bartMachine after preprocess... 223 total features...\n",
      "bartMachine sigsq estimated...\n",
      "bartMachine training data finalized...\n",
      "Now building bartMachine for classification ...Covariate importance prior ON. Missing data feature ON. \n",
      "evaluating in sample data...done\n"
     ]
    }
   ],
   "source": [
    "fits[['status_group.functional.needs.repair balanced']] <- bartMachine(undersampled[,predictors],\n",
    "                                                              factor(undersampled[,'status_group.functional.needs.repair']),\n",
    "                                                              use_missing_data = TRUE, mem_cache_for_speed = FALSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>'0'</li>\n",
       "\t<li>'1'</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item '0'\n",
       "\\item '1'\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. '0'\n",
       "2. '1'\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] \"0\" \"1\""
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "levels(factor(undersampled[,'status_group.functional.needs.repair']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in vapply(seq_along(mapped), function(i) {: values must be length 1,\n but FUN(X[[1]]) result is length 0\n",
     "output_type": "error",
     "traceback": [
      "Error in vapply(seq_along(mapped), function(i) {: values must be length 1,\n but FUN(X[[1]]) result is length 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "$status_group.functional\n",
       "bartMachine v1.2.1 for classification\n",
       "\n",
       "Missing data feature ON\n",
       "training data n = 47522 and p = 225 \n",
       "built in 3.53 mins on 3 cores, 50 trees, 250 burn-in and 1000 post. samples\n",
       "\n",
       "confusion matrix:\n",
       "\n",
       "           predicted 0 predicted 1 model errors\n",
       "actual 0     15117.000    6597.000        0.304\n",
       "actual 1      3055.000   22753.000        0.118\n",
       "use errors       0.168       0.225        0.203\n",
       "\n",
       "\n",
       "$status_group.functional.needs.repair\n",
       "bartMachine v1.2.1 for classification\n",
       "\n",
       "Missing data feature ON\n",
       "training data n = 47522 and p = 225 \n",
       "built in 3.78 mins on 3 cores, 50 trees, 250 burn-in and 1000 post. samples\n",
       "\n",
       "confusion matrix:\n",
       "\n",
       "           predicted 0 predicted 1 model errors\n",
       "actual 0     43926.000     142.000        0.003\n",
       "actual 1      3110.000     344.000        0.900\n",
       "use errors       0.066       0.292        0.068\n",
       "\n",
       "\n",
       "$status_group.non.functional\n",
       "bartMachine v1.2.1 for classification\n",
       "\n",
       "Missing data feature ON\n",
       "training data n = 47522 and p = 225 \n",
       "built in 3.47 mins on 3 cores, 50 trees, 250 burn-in and 1000 post. samples\n",
       "\n",
       "confusion matrix:\n",
       "\n",
       "           predicted 0 predicted 1 model errors\n",
       "actual 0     27322.000    1940.000        0.066\n",
       "actual 1      6239.000   12021.000        0.342\n",
       "use errors       0.186       0.139        0.172\n",
       "\n",
       "\n",
       "$`status_group.functional.needs.repair balanced`\n",
       "bartMachine v1.2.1 for classification\n",
       "\n",
       "Missing data feature ON\n",
       "training data n = 6908 and p = 222 \n",
       "built in 34.6 secs on 3 cores, 50 trees, 250 burn-in and 1000 post. samples\n",
       "\n",
       "confusion matrix:\n",
       "\n",
       "           predicted 0 predicted 1 model errors\n",
       "actual 0      2580.000     874.000        0.253\n",
       "actual 1       663.000    2791.000        0.192\n",
       "use errors       0.204       0.238        0.222\n",
       "\n"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>'status_group.functional'</li>\n",
       "\t<li>'status_group.functional.needs.repair'</li>\n",
       "\t<li>'status_group.non.functional'</li>\n",
       "\t<li>'status_group.functional.needs.repair balanced'</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 'status_group.functional'\n",
       "\\item 'status_group.functional.needs.repair'\n",
       "\\item 'status_group.non.functional'\n",
       "\\item 'status_group.functional.needs.repair balanced'\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 'status_group.functional'\n",
       "2. 'status_group.functional.needs.repair'\n",
       "3. 'status_group.non.functional'\n",
       "4. 'status_group.functional.needs.repair balanced'\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] \"status_group.functional\"                      \n",
       "[2] \"status_group.functional.needs.repair\"         \n",
       "[3] \"status_group.non.functional\"                  \n",
       "[4] \"status_group.functional.needs.repair balanced\""
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names(fits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".....\n"
     ]
    }
   ],
   "source": [
    "varImportance <- investigate_var_importance(fits[[1]], plot = FALSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<dl class=dl-horizontal>\n",
       "\t<dt>construction_year</dt>\n",
       "\t\t<dd>0.0582562860971122</dd>\n",
       "\t<dt>longitude</dt>\n",
       "\t\t<dd>0.0526538825576417</dd>\n",
       "\t<dt>latitude</dt>\n",
       "\t\t<dd>0.0513035931976112</dd>\n",
       "\t<dt>date_recorded</dt>\n",
       "\t\t<dd>0.0336284662525952</dd>\n",
       "\t<dt>date_recorded_month</dt>\n",
       "\t\t<dd>0.0287358107896173</dd>\n",
       "\t<dt>population</dt>\n",
       "\t\t<dd>0.0273173095621869</dd>\n",
       "\t<dt>amount_tsh</dt>\n",
       "\t\t<dd>0.0247302023976833</dd>\n",
       "\t<dt>date_recorded_year_ago</dt>\n",
       "\t\t<dd>0.0242195328996289</dd>\n",
       "\t<dt>date_recorded_year</dt>\n",
       "\t\t<dd>0.0224741873100578</dd>\n",
       "\t<dt>date_recorded_day</dt>\n",
       "\t\t<dd>0.0202296517824154</dd>\n",
       "</dl>\n"
      ],
      "text/latex": [
       "\\begin{description*}\n",
       "\\item[construction_year] 0.0582562860971122\n",
       "\\item[longitude] 0.0526538825576417\n",
       "\\item[latitude] 0.0513035931976112\n",
       "\\item[date_recorded] 0.0336284662525952\n",
       "\\item[date_recorded_month] 0.0287358107896173\n",
       "\\item[population] 0.0273173095621869\n",
       "\\item[amount_tsh] 0.0247302023976833\n",
       "\\item[date_recorded_year_ago] 0.0242195328996289\n",
       "\\item[date_recorded_year] 0.0224741873100578\n",
       "\\item[date_recorded_day] 0.0202296517824154\n",
       "\\end{description*}\n"
      ],
      "text/markdown": [
       "construction_year\n",
       ":   0.0582562860971122longitude\n",
       ":   0.0526538825576417latitude\n",
       ":   0.0513035931976112date_recorded\n",
       ":   0.0336284662525952date_recorded_month\n",
       ":   0.0287358107896173population\n",
       ":   0.0273173095621869amount_tsh\n",
       ":   0.0247302023976833date_recorded_year_ago\n",
       ":   0.0242195328996289date_recorded_year\n",
       ":   0.0224741873100578date_recorded_day\n",
       ":   0.0202296517824154\n",
       "\n"
      ],
      "text/plain": [
       "     construction_year              longitude               latitude \n",
       "            0.05825629             0.05265388             0.05130359 \n",
       "         date_recorded    date_recorded_month             population \n",
       "            0.03362847             0.02873581             0.02731731 \n",
       "            amount_tsh date_recorded_year_ago     date_recorded_year \n",
       "            0.02473020             0.02421953             0.02247419 \n",
       "     date_recorded_day \n",
       "            0.02022965 "
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "head(varImportance$avg_var_props, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Needs repair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".....\n"
     ]
    }
   ],
   "source": [
    "varImportance2 <- investigate_var_importance(fits[[2]], plot = FALSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<dl class=dl-horizontal>\n",
       "\t<dt>latitude</dt>\n",
       "\t\t<dd>0.0593661763815799</dd>\n",
       "\t<dt>longitude</dt>\n",
       "\t\t<dd>0.0548710866596019</dd>\n",
       "\t<dt>construction_year</dt>\n",
       "\t\t<dd>0.0441631820272221</dd>\n",
       "\t<dt>date_recorded_month</dt>\n",
       "\t\t<dd>0.040727948985578</dd>\n",
       "\t<dt>date_recorded</dt>\n",
       "\t\t<dd>0.0390347271273005</dd>\n",
       "\t<dt>date_recorded_year</dt>\n",
       "\t\t<dd>0.027588061814973</dd>\n",
       "\t<dt>date_recorded_year_ago</dt>\n",
       "\t\t<dd>0.019941813891776</dd>\n",
       "\t<dt>date_recorded_day</dt>\n",
       "\t\t<dd>0.0195712461712801</dd>\n",
       "\t<dt>population</dt>\n",
       "\t\t<dd>0.0194791203655007</dd>\n",
       "\t<dt>amount_tsh</dt>\n",
       "\t\t<dd>0.0143156603366373</dd>\n",
       "</dl>\n"
      ],
      "text/latex": [
       "\\begin{description*}\n",
       "\\item[latitude] 0.0593661763815799\n",
       "\\item[longitude] 0.0548710866596019\n",
       "\\item[construction_year] 0.0441631820272221\n",
       "\\item[date_recorded_month] 0.040727948985578\n",
       "\\item[date_recorded] 0.0390347271273005\n",
       "\\item[date_recorded_year] 0.027588061814973\n",
       "\\item[date_recorded_year_ago] 0.019941813891776\n",
       "\\item[date_recorded_day] 0.0195712461712801\n",
       "\\item[population] 0.0194791203655007\n",
       "\\item[amount_tsh] 0.0143156603366373\n",
       "\\end{description*}\n"
      ],
      "text/markdown": [
       "latitude\n",
       ":   0.0593661763815799longitude\n",
       ":   0.0548710866596019construction_year\n",
       ":   0.0441631820272221date_recorded_month\n",
       ":   0.040727948985578date_recorded\n",
       ":   0.0390347271273005date_recorded_year\n",
       ":   0.027588061814973date_recorded_year_ago\n",
       ":   0.019941813891776date_recorded_day\n",
       ":   0.0195712461712801population\n",
       ":   0.0194791203655007amount_tsh\n",
       ":   0.0143156603366373\n",
       "\n"
      ],
      "text/plain": [
       "              latitude              longitude      construction_year \n",
       "            0.05936618             0.05487109             0.04416318 \n",
       "   date_recorded_month          date_recorded     date_recorded_year \n",
       "            0.04072795             0.03903473             0.02758806 \n",
       "date_recorded_year_ago      date_recorded_day             population \n",
       "            0.01994181             0.01957125             0.01947912 \n",
       "            amount_tsh \n",
       "            0.01431566 "
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "head(varImportance2$avg_var_props, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "'date_recorded_year_ago'"
      ],
      "text/latex": [
       "'date_recorded_year_ago'"
      ],
      "text/markdown": [
       "'date_recorded_year_ago'"
      ],
      "text/plain": [
       "[1] \"date_recorded_year_ago\""
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grep('date_recorded_year_.*', names(varImportance2$avg_var_props), value = TRUE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Non functional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".....\n"
     ]
    }
   ],
   "source": [
    "varImportance3 <- investigate_var_importance(fits[[3]], plot = FALSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<dl class=dl-horizontal>\n",
       "\t<dt>construction_year</dt>\n",
       "\t\t<dd>0.0563999494078947</dd>\n",
       "\t<dt>latitude</dt>\n",
       "\t\t<dd>0.0435791444430137</dd>\n",
       "\t<dt>longitude</dt>\n",
       "\t\t<dd>0.0433773637974994</dd>\n",
       "\t<dt>date_recorded</dt>\n",
       "\t\t<dd>0.0356266703058368</dd>\n",
       "\t<dt>date_recorded_month</dt>\n",
       "\t\t<dd>0.0291200565104315</dd>\n",
       "\t<dt>population</dt>\n",
       "\t\t<dd>0.0270689679749215</dd>\n",
       "\t<dt>date_recorded_year_ago</dt>\n",
       "\t\t<dd>0.0235973841738024</dd>\n",
       "\t<dt>amount_tsh</dt>\n",
       "\t\t<dd>0.023271806136605</dd>\n",
       "\t<dt>date_recorded_year</dt>\n",
       "\t\t<dd>0.0212156719053385</dd>\n",
       "\t<dt>date_recorded_day</dt>\n",
       "\t\t<dd>0.0162329478107204</dd>\n",
       "</dl>\n"
      ],
      "text/latex": [
       "\\begin{description*}\n",
       "\\item[construction_year] 0.0563999494078947\n",
       "\\item[latitude] 0.0435791444430137\n",
       "\\item[longitude] 0.0433773637974994\n",
       "\\item[date_recorded] 0.0356266703058368\n",
       "\\item[date_recorded_month] 0.0291200565104315\n",
       "\\item[population] 0.0270689679749215\n",
       "\\item[date_recorded_year_ago] 0.0235973841738024\n",
       "\\item[amount_tsh] 0.023271806136605\n",
       "\\item[date_recorded_year] 0.0212156719053385\n",
       "\\item[date_recorded_day] 0.0162329478107204\n",
       "\\end{description*}\n"
      ],
      "text/markdown": [
       "construction_year\n",
       ":   0.0563999494078947latitude\n",
       ":   0.0435791444430137longitude\n",
       ":   0.0433773637974994date_recorded\n",
       ":   0.0356266703058368date_recorded_month\n",
       ":   0.0291200565104315population\n",
       ":   0.0270689679749215date_recorded_year_ago\n",
       ":   0.0235973841738024amount_tsh\n",
       ":   0.023271806136605date_recorded_year\n",
       ":   0.0212156719053385date_recorded_day\n",
       ":   0.0162329478107204\n",
       "\n"
      ],
      "text/plain": [
       "     construction_year               latitude              longitude \n",
       "            0.05639995             0.04357914             0.04337736 \n",
       "         date_recorded    date_recorded_month             population \n",
       "            0.03562667             0.02912006             0.02706897 \n",
       "date_recorded_year_ago             amount_tsh     date_recorded_year \n",
       "            0.02359738             0.02327181             0.02121567 \n",
       "     date_recorded_day \n",
       "            0.01623295 "
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "head(varImportance3$avg_var_props, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Needs repair - balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "varImportance4 <- investigate_var_importance(fits[[4]], plot = FALSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<dl class=dl-horizontal>\n",
       "\t<dt>latitude</dt>\n",
       "\t\t<dd>0.0652612453014946</dd>\n",
       "\t<dt>date_recorded</dt>\n",
       "\t\t<dd>0.0480479556463547</dd>\n",
       "\t<dt>longitude</dt>\n",
       "\t\t<dd>0.047760956602992</dd>\n",
       "\t<dt>construction_year</dt>\n",
       "\t\t<dd>0.0456974680341195</dd>\n",
       "\t<dt>date_recorded_month</dt>\n",
       "\t\t<dd>0.0317462052341599</dd>\n",
       "\t<dt>date_recorded_year</dt>\n",
       "\t\t<dd>0.0261530543195645</dd>\n",
       "\t<dt>date_recorded_year_ago</dt>\n",
       "\t\t<dd>0.0256958984294067</dd>\n",
       "\t<dt>date_recorded_day</dt>\n",
       "\t\t<dd>0.0196673190177613</dd>\n",
       "\t<dt>amount_tsh</dt>\n",
       "\t\t<dd>0.0135085973671405</dd>\n",
       "\t<dt>district_code_1</dt>\n",
       "\t\t<dd>0.0133892808263109</dd>\n",
       "</dl>\n"
      ],
      "text/latex": [
       "\\begin{description*}\n",
       "\\item[latitude] 0.0652612453014946\n",
       "\\item[date_recorded] 0.0480479556463547\n",
       "\\item[longitude] 0.047760956602992\n",
       "\\item[construction_year] 0.0456974680341195\n",
       "\\item[date_recorded_month] 0.0317462052341599\n",
       "\\item[date_recorded_year] 0.0261530543195645\n",
       "\\item[date_recorded_year_ago] 0.0256958984294067\n",
       "\\item[date_recorded_day] 0.0196673190177613\n",
       "\\item[amount_tsh] 0.0135085973671405\n",
       "\\item[district_code_1] 0.0133892808263109\n",
       "\\end{description*}\n"
      ],
      "text/markdown": [
       "latitude\n",
       ":   0.0652612453014946date_recorded\n",
       ":   0.0480479556463547longitude\n",
       ":   0.047760956602992construction_year\n",
       ":   0.0456974680341195date_recorded_month\n",
       ":   0.0317462052341599date_recorded_year\n",
       ":   0.0261530543195645date_recorded_year_ago\n",
       ":   0.0256958984294067date_recorded_day\n",
       ":   0.0196673190177613amount_tsh\n",
       ":   0.0135085973671405district_code_1\n",
       ":   0.0133892808263109\n",
       "\n"
      ],
      "text/plain": [
       "              latitude          date_recorded              longitude \n",
       "            0.06526125             0.04804796             0.04776096 \n",
       "     construction_year    date_recorded_month     date_recorded_year \n",
       "            0.04569747             0.03174621             0.02615305 \n",
       "date_recorded_year_ago      date_recorded_day             amount_tsh \n",
       "            0.02569590             0.01966732             0.01350860 \n",
       "       district_code_1 \n",
       "            0.01338928 "
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "head(varImportance4$avg_var_props, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message:\n",
      "In pre_process_new_data(new_data, bart_machine): The following features were found in records for prediction which were not found in the original training data:\n",
      "    region_code_40, scheme_management_None, extraction_type_other - mkulima/shinyanga\n",
      "  These features will be ignored during prediction."
     ]
    }
   ],
   "source": [
    "preds <- list()\n",
    "for(outcome in c('status_group.functional', 'status_group.non.functional', \n",
    "                 'status_group.functional.needs.repair', 'status_group.functional.needs.repair balanced')) {\n",
    "  preds[[outcome]] <- predict(fits[[outcome]], training[,predictors])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>status_group.functional</th><th scope=col>status_group.non.functional</th><th scope=col>status_group.functional.needs.repair</th><th scope=col>status_group.functional.needs.repair balanced</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>0.978495270</td><td>0.008162931</td><td>0.012413910</td><td>0.128351265</td></tr>\n",
       "\t<tr><td>0.801847786</td><td>0.219599288</td><td>0.009314847</td><td>0.265126798</td></tr>\n",
       "\t<tr><td>0.7280951</td><td>0.1212882</td><td>0.1608879</td><td>0.5104547</td></tr>\n",
       "\t<tr><td>0.935521044</td><td>0.157679508</td><td>0.006689232</td><td>0.120229342</td></tr>\n",
       "\t<tr><td>0.53781501</td><td>0.42300008</td><td>0.01678798</td><td>0.13228723</td></tr>\n",
       "\t<tr><td>0.555369574</td><td>0.580648887</td><td>0.006291532</td><td>0.301583529</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{llll}\n",
       " status_group.functional & status_group.non.functional & status_group.functional.needs.repair & status_group.functional.needs.repair balanced\\\\\n",
       "\\hline\n",
       "\t 0.978495270 & 0.008162931 & 0.012413910 & 0.128351265\\\\\n",
       "\t 0.801847786 & 0.219599288 & 0.009314847 & 0.265126798\\\\\n",
       "\t 0.7280951 & 0.1212882 & 0.1608879 & 0.5104547\\\\\n",
       "\t 0.935521044 & 0.157679508 & 0.006689232 & 0.120229342\\\\\n",
       "\t 0.53781501 & 0.42300008 & 0.01678798 & 0.13228723\\\\\n",
       "\t 0.555369574 & 0.580648887 & 0.006291532 & 0.301583529\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "1. 0.978495269709017\n",
       "2. 0.801847786115461\n",
       "3. 0.728095050887123\n",
       "4. 0.93552104354403\n",
       "5. 0.537815014965278\n",
       "6. 0.55536957363102\n",
       "7. 0.00816293082224676\n",
       "8. 0.219599288020789\n",
       "9. 0.121288187382009\n",
       "10. 0.157679507667596\n",
       "11. 0.423000081072331\n",
       "12. 0.580648886808886\n",
       "13. 0.0124139103931356\n",
       "14. 0.00931484729581643\n",
       "15. 0.160887919198216\n",
       "16. 0.00668923168745664\n",
       "17. 0.0167879812374555\n",
       "18. 0.00629153170270756\n",
       "19. 0.128351264906013\n",
       "20. 0.265126797822785\n",
       "21. 0.510454679958702\n",
       "22. 0.120229341555122\n",
       "23. 0.132287227456247\n",
       "24. 0.301583528790731\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "     status_group.functional status_group.non.functional\n",
       "[1,]               0.9784953                 0.008162931\n",
       "[2,]               0.8018478                 0.219599288\n",
       "[3,]               0.7280951                 0.121288187\n",
       "[4,]               0.9355210                 0.157679508\n",
       "[5,]               0.5378150                 0.423000081\n",
       "[6,]               0.5553696                 0.580648887\n",
       "     status_group.functional.needs.repair\n",
       "[1,]                          0.012413910\n",
       "[2,]                          0.009314847\n",
       "[3,]                          0.160887919\n",
       "[4,]                          0.006689232\n",
       "[5,]                          0.016787981\n",
       "[6,]                          0.006291532\n",
       "     status_group.functional.needs.repair balanced\n",
       "[1,]                                     0.1283513\n",
       "[2,]                                     0.2651268\n",
       "[3,]                                     0.5104547\n",
       "[4,]                                     0.1202293\n",
       "[5,]                                     0.1322872\n",
       "[6,]                                     0.3015835"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sapply(preds, head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"status_group.functional\"\n",
      "Confusion Matrix and Statistics\n",
      "\n",
      "          Reference\n",
      "Prediction FALSE  TRUE\n",
      "     FALSE 15117  3055\n",
      "     TRUE   6597 22753\n",
      "                                          \n",
      "               Accuracy : 0.7969          \n",
      "                 95% CI : (0.7932, 0.8005)\n",
      "    No Information Rate : 0.5431          \n",
      "    P-Value [Acc > NIR] : < 2.2e-16       \n",
      "                                          \n",
      "                  Kappa : 0.5854          \n",
      " Mcnemar's Test P-Value : < 2.2e-16       \n",
      "                                          \n",
      "            Sensitivity : 0.6962          \n",
      "            Specificity : 0.8816          \n",
      "         Pos Pred Value : 0.8319          \n",
      "         Neg Pred Value : 0.7752          \n",
      "             Prevalence : 0.4569          \n",
      "         Detection Rate : 0.3181          \n",
      "   Detection Prevalence : 0.3824          \n",
      "      Balanced Accuracy : 0.7889          \n",
      "                                          \n",
      "       'Positive' Class : FALSE           \n",
      "                                          \n",
      "[1] \"status_group.non.functional\"\n",
      "Confusion Matrix and Statistics\n",
      "\n",
      "          Reference\n",
      "Prediction FALSE  TRUE\n",
      "     FALSE 27322  6239\n",
      "     TRUE   1940 12021\n",
      "                                          \n",
      "               Accuracy : 0.8279          \n",
      "                 95% CI : (0.8245, 0.8313)\n",
      "    No Information Rate : 0.6158          \n",
      "    P-Value [Acc > NIR] : < 2.2e-16       \n",
      "                                          \n",
      "                  Kappa : 0.6194          \n",
      " Mcnemar's Test P-Value : < 2.2e-16       \n",
      "                                          \n",
      "            Sensitivity : 0.9337          \n",
      "            Specificity : 0.6583          \n",
      "         Pos Pred Value : 0.8141          \n",
      "         Neg Pred Value : 0.8610          \n",
      "             Prevalence : 0.6158          \n",
      "         Detection Rate : 0.5749          \n",
      "   Detection Prevalence : 0.7062          \n",
      "      Balanced Accuracy : 0.7960          \n",
      "                                          \n",
      "       'Positive' Class : FALSE           \n",
      "                                          \n",
      "[1] \"status_group.functional.needs.repair\"\n",
      "Confusion Matrix and Statistics\n",
      "\n",
      "          Reference\n",
      "Prediction FALSE  TRUE\n",
      "     FALSE 43926  3110\n",
      "     TRUE    142   344\n",
      "                                          \n",
      "               Accuracy : 0.9316          \n",
      "                 95% CI : (0.9293, 0.9338)\n",
      "    No Information Rate : 0.9273          \n",
      "    P-Value [Acc > NIR] : 0.000165        \n",
      "                                          \n",
      "                  Kappa : 0.1595          \n",
      " Mcnemar's Test P-Value : < 2.2e-16       \n",
      "                                          \n",
      "            Sensitivity : 0.99678         \n",
      "            Specificity : 0.09959         \n",
      "         Pos Pred Value : 0.93388         \n",
      "         Neg Pred Value : 0.70782         \n",
      "             Prevalence : 0.92732         \n",
      "         Detection Rate : 0.92433         \n",
      "   Detection Prevalence : 0.98977         \n",
      "      Balanced Accuracy : 0.54819         \n",
      "                                          \n",
      "       'Positive' Class : FALSE           \n",
      "                                          \n"
     ]
    }
   ],
   "source": [
    "for(outcome in c('status_group.functional', 'status_group.non.functional', 'status_group.functional.needs.repair')) {\n",
    "    print(outcome)\n",
    "    print(confusionMatrix(preds[[outcome]] > 0.5, training[,outcome] == 1))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"status_group.functional\"\n",
      "Confusion Matrix and Statistics\n",
      "\n",
      "          Reference\n",
      "Prediction FALSE TRUE\n",
      "     FALSE  3708  783\n",
      "     TRUE   1719 5668\n",
      "                                          \n",
      "               Accuracy : 0.7894          \n",
      "                 95% CI : (0.7819, 0.7967)\n",
      "    No Information Rate : 0.5431          \n",
      "    P-Value [Acc > NIR] : < 2.2e-16       \n",
      "                                          \n",
      "                  Kappa : 0.5697          \n",
      " Mcnemar's Test P-Value : < 2.2e-16       \n",
      "                                          \n",
      "            Sensitivity : 0.6833          \n",
      "            Specificity : 0.8786          \n",
      "         Pos Pred Value : 0.8257          \n",
      "         Neg Pred Value : 0.7673          \n",
      "             Prevalence : 0.4569          \n",
      "         Detection Rate : 0.3122          \n",
      "   Detection Prevalence : 0.3781          \n",
      "      Balanced Accuracy : 0.7809          \n",
      "                                          \n",
      "       'Positive' Class : FALSE           \n",
      "                                          \n",
      "[1] \"status_group.non.functional\"\n",
      "Confusion Matrix and Statistics\n",
      "\n",
      "          Reference\n",
      "Prediction FALSE TRUE\n",
      "     FALSE  6797 1577\n",
      "     TRUE    517 2987\n",
      "                                          \n",
      "               Accuracy : 0.8237          \n",
      "                 95% CI : (0.8167, 0.8305)\n",
      "    No Information Rate : 0.6158          \n",
      "    P-Value [Acc > NIR] : < 2.2e-16       \n",
      "                                          \n",
      "                  Kappa : 0.6104          \n",
      " Mcnemar's Test P-Value : < 2.2e-16       \n",
      "                                          \n",
      "            Sensitivity : 0.9293          \n",
      "            Specificity : 0.6545          \n",
      "         Pos Pred Value : 0.8117          \n",
      "         Neg Pred Value : 0.8525          \n",
      "             Prevalence : 0.6158          \n",
      "         Detection Rate : 0.5722          \n",
      "   Detection Prevalence : 0.7050          \n",
      "      Balanced Accuracy : 0.7919          \n",
      "                                          \n",
      "       'Positive' Class : FALSE           \n",
      "                                          \n",
      "[1] \"status_group.functional.needs.repair\"\n",
      "Confusion Matrix and Statistics\n",
      "\n",
      "          Reference\n",
      "Prediction FALSE  TRUE\n",
      "     FALSE 10977   775\n",
      "     TRUE     38    88\n",
      "                                         \n",
      "               Accuracy : 0.9316         \n",
      "                 95% CI : (0.9269, 0.936)\n",
      "    No Information Rate : 0.9273         \n",
      "    P-Value [Acc > NIR] : 0.03916        \n",
      "                                         \n",
      "                  Kappa : 0.1625         \n",
      " Mcnemar's Test P-Value : < 2e-16        \n",
      "                                         \n",
      "            Sensitivity : 0.9966         \n",
      "            Specificity : 0.1020         \n",
      "         Pos Pred Value : 0.9341         \n",
      "         Neg Pred Value : 0.6984         \n",
      "             Prevalence : 0.9273         \n",
      "         Detection Rate : 0.9241         \n",
      "   Detection Prevalence : 0.9894         \n",
      "      Balanced Accuracy : 0.5493         \n",
      "                                         \n",
      "       'Positive' Class : FALSE          \n",
      "                                         \n"
     ]
    }
   ],
   "source": [
    "predsTesting <- list()\n",
    "for(outcome in c('status_group.functional', 'status_group.non.functional', 'status_group.functional.needs.repair',\n",
    "                'status_group.functional.needs.repair balanced')) {\n",
    "  predsTesting[[outcome]] <- predict(fits[[outcome]], testing[,predictors])\n",
    "}\n",
    "for(outcome in c('status_group.functional', 'status_group.non.functional', 'status_group.functional.needs.repair')) {\n",
    "    print(outcome)\n",
    "    print(confusionMatrix(predsTesting[[outcome]] > 0.5, testing[,outcome] == 1))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predsDf <- data.frame('functional' = preds$status_group.functional,\n",
    "                      'needrepair' = preds$`status_group.functional.needs.repair balanced`,\n",
    "#                      'needrepair' = preds$status_group.functional.needs.repair,\n",
    "                      'nonfunctional' = preds$status_group.non.functional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th></th><th scope=col>functional</th><th scope=col>needrepair</th><th scope=col>nonfunctional</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>1</th><td>0.9784953</td><td>0.1283513</td><td>0.008162931</td></tr>\n",
       "\t<tr><th scope=row>2</th><td>0.8018478</td><td>0.2651268</td><td>0.2195993</td></tr>\n",
       "\t<tr><th scope=row>3</th><td>0.7280951</td><td>0.5104547</td><td>0.1212882</td></tr>\n",
       "\t<tr><th scope=row>4</th><td>0.935521</td><td>0.1202293</td><td>0.1576795</td></tr>\n",
       "\t<tr><th scope=row>5</th><td>0.537815</td><td>0.1322872</td><td>0.4230001</td></tr>\n",
       "\t<tr><th scope=row>6</th><td>0.5553696</td><td>0.3015835</td><td>0.5806489</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|lll}\n",
       "  & functional & needrepair & nonfunctional\\\\\n",
       "\\hline\n",
       "\t1 & 0.9784953 & 0.1283513 & 0.008162931\\\\\n",
       "\t2 & 0.8018478 & 0.2651268 & 0.2195993\\\\\n",
       "\t3 & 0.7280951 & 0.5104547 & 0.1212882\\\\\n",
       "\t4 & 0.935521 & 0.1202293 & 0.1576795\\\\\n",
       "\t5 & 0.537815 & 0.1322872 & 0.4230001\\\\\n",
       "\t6 & 0.5553696 & 0.3015835 & 0.5806489\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "  functional needrepair nonfunctional\n",
       "1  0.9784953  0.1283513   0.008162931\n",
       "2  0.8018478  0.2651268   0.219599288\n",
       "3  0.7280951  0.5104547   0.121288187\n",
       "4  0.9355210  0.1202293   0.157679508\n",
       "5  0.5378150  0.1322872   0.423000081\n",
       "6  0.5553696  0.3015835   0.580648887"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "head(predsDf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th></th><th scope=col>functional</th><th scope=col>functional needs repair</th><th scope=col>non functional</th><th scope=col>prediction</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>1</th><td>0.9784953</td><td>0.1283513</td><td>0.008162931</td><td>functional</td></tr>\n",
       "\t<tr><th scope=row>2</th><td>0.8018478</td><td>0.2651268</td><td>0.2195993</td><td>functional</td></tr>\n",
       "\t<tr><th scope=row>3</th><td>0.7280951</td><td>0.5104547</td><td>0.1212882</td><td>functional</td></tr>\n",
       "\t<tr><th scope=row>4</th><td>0.935521</td><td>0.1202293</td><td>0.1576795</td><td>functional</td></tr>\n",
       "\t<tr><th scope=row>5</th><td>0.537815</td><td>0.1322872</td><td>0.4230001</td><td>functional</td></tr>\n",
       "\t<tr><th scope=row>6</th><td>0.5553696</td><td>0.3015835</td><td>0.5806489</td><td>non functional</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|llll}\n",
       "  & functional & functional needs repair & non functional & prediction\\\\\n",
       "\\hline\n",
       "\t1 & 0.9784953 & 0.1283513 & 0.008162931 & functional\\\\\n",
       "\t2 & 0.8018478 & 0.2651268 & 0.2195993 & functional\\\\\n",
       "\t3 & 0.7280951 & 0.5104547 & 0.1212882 & functional\\\\\n",
       "\t4 & 0.935521 & 0.1202293 & 0.1576795 & functional\\\\\n",
       "\t5 & 0.537815 & 0.1322872 & 0.4230001 & functional\\\\\n",
       "\t6 & 0.5553696 & 0.3015835 & 0.5806489 & non functional\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "Source: local data frame [6 x 4]\n",
       "\n",
       "  functional functional needs repair non functional     prediction\n",
       "       (dbl)                   (dbl)          (dbl)         (fctr)\n",
       "1  0.9784953               0.1283513    0.008162931     functional\n",
       "2  0.8018478               0.2651268    0.219599288     functional\n",
       "3  0.7280951               0.5104547    0.121288187     functional\n",
       "4  0.9355210               0.1202293    0.157679508     functional\n",
       "5  0.5378150               0.1322872    0.423000081     functional\n",
       "6  0.5553696               0.3015835    0.580648887 non functional"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "library(dplyr)\n",
    "\n",
    "colnames(predsDf) <- c('functional', 'functional needs repair', 'non functional')\n",
    "predictionLevels <- factor(colnames(predsDf))\n",
    "predictions <- predsDf %>%\n",
    "                  rowwise() %>% \n",
    "                  mutate(prediction=predictionLevels[which.max(c(functional, `functional needs repair`, `non functional`))])\n",
    "\n",
    "head(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "             functional functional needs repair          non functional \n",
       "                  25801                    8546                   13175 "
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table(predictions$prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "47522"
      ],
      "text/latex": [
       "47522"
      ],
      "text/markdown": [
       "47522"
      ],
      "text/plain": [
       "[1] 47522"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "47522"
      ],
      "text/latex": [
       "47522"
      ],
      "text/markdown": [
       "47522"
      ],
      "text/plain": [
       "[1] 47522"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th></th><th scope=col>functional</th><th scope=col>functional needs repair</th><th scope=col>non functional</th><th scope=col>prediction</th><th scope=col>status_group</th><th scope=col>status_group.functional.needs.repair</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>1</th><td>0.9784953</td><td>0.1283513</td><td>0.008162931</td><td>functional</td><td>functional</td><td>0</td></tr>\n",
       "\t<tr><th scope=row>2</th><td>0.8018478</td><td>0.2651268</td><td>0.2195993</td><td>functional</td><td>functional</td><td>0</td></tr>\n",
       "\t<tr><th scope=row>3</th><td>0.7280951</td><td>0.5104547</td><td>0.1212882</td><td>functional</td><td>functional</td><td>0</td></tr>\n",
       "\t<tr><th scope=row>4</th><td>0.935521</td><td>0.1202293</td><td>0.1576795</td><td>functional</td><td>functional</td><td>0</td></tr>\n",
       "\t<tr><th scope=row>5</th><td>0.537815</td><td>0.1322872</td><td>0.4230001</td><td>functional</td><td>non functional</td><td>0</td></tr>\n",
       "\t<tr><th scope=row>6</th><td>0.5553696</td><td>0.3015835</td><td>0.5806489</td><td>non functional</td><td>non functional</td><td>0</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|llllll}\n",
       "  & functional & functional needs repair & non functional & prediction & status_group & status_group.functional.needs.repair\\\\\n",
       "\\hline\n",
       "\t1 & 0.9784953 & 0.1283513 & 0.008162931 & functional & functional & 0\\\\\n",
       "\t2 & 0.8018478 & 0.2651268 & 0.2195993 & functional & functional & 0\\\\\n",
       "\t3 & 0.7280951 & 0.5104547 & 0.1212882 & functional & functional & 0\\\\\n",
       "\t4 & 0.935521 & 0.1202293 & 0.1576795 & functional & functional & 0\\\\\n",
       "\t5 & 0.537815 & 0.1322872 & 0.4230001 & functional & non functional & 0\\\\\n",
       "\t6 & 0.5553696 & 0.3015835 & 0.5806489 & non functional & non functional & 0\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "  functional functional needs repair non functional     prediction\n",
       "1  0.9784953               0.1283513    0.008162931     functional\n",
       "2  0.8018478               0.2651268    0.219599288     functional\n",
       "3  0.7280951               0.5104547    0.121288187     functional\n",
       "4  0.9355210               0.1202293    0.157679508     functional\n",
       "5  0.5378150               0.1322872    0.423000081     functional\n",
       "6  0.5553696               0.3015835    0.580648887 non functional\n",
       "    status_group status_group.functional.needs.repair\n",
       "1     functional                                    0\n",
       "2     functional                                    0\n",
       "3     functional                                    0\n",
       "4     functional                                    0\n",
       "5 non functional                                    0\n",
       "6 non functional                                    0"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "length(predictions$prediction)\n",
    "length(training$status_group)\n",
    "predsForVote <- cbind(predictions, training$status_group)\n",
    "colnames(predsForVote) <- c('functional', 'functional needs repair', 'non functional', 'prediction', 'status_group')\n",
    "predsForVote$status_group.functional.needs.repair <- factor(training[,'status_group.functional.needs.repair'])\n",
    "head(predsForVote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fitglm <- glm(status_group.functional.needs.repair ~  functional + `functional needs repair` + `non functional`, predsForVote,\n",
    "             family = binomial)\n",
    "#?predict.glm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "Call:\n",
       "glm(formula = status_group.functional.needs.repair ~ functional + \n",
       "    `functional needs repair` + `non functional`, family = binomial, \n",
       "    data = predsForVote)\n",
       "\n",
       "Deviance Residuals: \n",
       "    Min       1Q   Median       3Q      Max  \n",
       "-1.9932  -0.3435  -0.1993  -0.1361   3.3100  \n",
       "\n",
       "Coefficients:\n",
       "                          Estimate Std. Error z value Pr(>|z|)    \n",
       "(Intercept)               -0.08233    0.22149  -0.372     0.71    \n",
       "functional                -4.93877    0.19535 -25.282   <2e-16 ***\n",
       "`functional needs repair`  3.73641    0.12757  29.289   <2e-16 ***\n",
       "`non functional`          -5.16327    0.21019 -24.565   <2e-16 ***\n",
       "---\n",
       "Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n",
       "\n",
       "(Dispersion parameter for binomial family taken to be 1)\n",
       "\n",
       "    Null deviance: 24761  on 47521  degrees of freedom\n",
       "Residual deviance: 18368  on 47518  degrees of freedom\n",
       "AIC: 18376\n",
       "\n",
       "Number of Fisher Scoring iterations: 6\n"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(fitglm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "library(rpart)\n",
    "fitrpart <- rpart(status_group ~  functional + `functional needs repair` + `non functional`, predsForVote,\n",
    "                 control = rpart.control(cp = 0.001))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Call:\n",
      "rpart(formula = status_group ~ functional + `functional needs repair` + \n",
      "    `non functional`, data = predsForVote, control = rpart.control(cp = 0.001))\n",
      "  n= 47522 \n",
      "\n",
      "           CP nsplit rel error    xerror        xstd\n",
      "1 0.490236714      0 1.0000000 1.0000000 0.005001035\n",
      "2 0.004305978      1 0.5097633 0.5099014 0.004243993\n",
      "3 0.002555955      4 0.4929539 0.4943815 0.004198180\n",
      "4 0.001335544      6 0.4878419 0.4914341 0.004189286\n",
      "5 0.001000000      7 0.4865064 0.4896841 0.004183976\n",
      "\n",
      "Variable importance\n",
      "         non functional              functional functional needs repair \n",
      "                     48                      41                      11 \n",
      "\n",
      "Node number 1: 47522 observations,    complexity param=0.4902367\n",
      "  predicted class=functional               expected loss=0.4569252  P(node) =1\n",
      "    class counts: 25808  3454 18260\n",
      "   probabilities: 0.543 0.073 0.384 \n",
      "  left son=2 (32421 obs) right son=3 (15101 obs)\n",
      "  Primary splits:\n",
      "      non functional          < 0.4608375  to the left,  improve=8314.339, (0 missing)\n",
      "      functional              < 0.4747222  to the right, improve=8035.407, (0 missing)\n",
      "      functional needs repair < 0.03184299 to the right, improve=1502.802, (0 missing)\n",
      "  Surrogate splits:\n",
      "      functional              < 0.3899742  to the right, agree=0.922, adj=0.754, (0 split)\n",
      "      functional needs repair < 0.05280544 to the right, agree=0.737, adj=0.172, (0 split)\n",
      "\n",
      "Node number 2: 32421 observations,    complexity param=0.004305978\n",
      "  predicted class=functional               expected loss=0.2654452  P(node) =0.6822314\n",
      "    class counts: 23815  2984  5622\n",
      "   probabilities: 0.735 0.092 0.173 \n",
      "  left son=4 (22435 obs) right son=5 (9986 obs)\n",
      "  Primary splits:\n",
      "      functional              < 0.6382887  to the right, improve=1166.8420, (0 missing)\n",
      "      non functional          < 0.2541391  to the left,  improve= 811.6353, (0 missing)\n",
      "      functional needs repair < 0.6452562  to the left,  improve= 563.6470, (0 missing)\n",
      "  Surrogate splits:\n",
      "      non functional          < 0.2861616  to the left,  agree=0.811, adj=0.386, (0 split)\n",
      "      functional needs repair < 0.672693   to the left,  agree=0.754, adj=0.200, (0 split)\n",
      "\n",
      "Node number 3: 15101 observations\n",
      "  predicted class=non functional           expected loss=0.1631018  P(node) =0.3177686\n",
      "    class counts:  1993   470 12638\n",
      "   probabilities: 0.132 0.031 0.837 \n",
      "\n",
      "Node number 4: 22435 observations\n",
      "  predicted class=functional               expected loss=0.1622911  P(node) =0.4720971\n",
      "    class counts: 18794  1029  2612\n",
      "   probabilities: 0.838 0.046 0.116 \n",
      "\n",
      "Node number 5: 9986 observations,    complexity param=0.004305978\n",
      "  predicted class=functional               expected loss=0.4971961  P(node) =0.2101343\n",
      "    class counts:  5021  1955  3010\n",
      "   probabilities: 0.503 0.196 0.301 \n",
      "  left son=10 (1992 obs) right son=11 (7994 obs)\n",
      "  Primary splits:\n",
      "      functional needs repair < 0.7856353  to the right, improve=275.5390, (0 missing)\n",
      "      functional              < 0.475374   to the right, improve=203.0199, (0 missing)\n",
      "      non functional          < 0.2339833  to the left,  improve=199.6518, (0 missing)\n",
      "  Surrogate splits:\n",
      "      non functional < 0.1104094  to the left,  agree=0.842, adj=0.206, (0 split)\n",
      "      functional     < 0.3040345  to the left,  agree=0.824, adj=0.117, (0 split)\n",
      "\n",
      "Node number 10: 1992 observations,    complexity param=0.004305978\n",
      "  predicted class=functional needs repair  expected loss=0.5326305  P(node) =0.04191743\n",
      "    class counts:   744   931   317\n",
      "   probabilities: 0.373 0.467 0.159 \n",
      "  left son=20 (864 obs) right son=21 (1128 obs)\n",
      "  Primary splits:\n",
      "      functional              < 0.475374   to the right, improve=70.02834, (0 missing)\n",
      "      functional needs repair < 0.8965352  to the left,  improve=33.51622, (0 missing)\n",
      "      non functional          < 0.3077163  to the left,  improve=30.52849, (0 missing)\n",
      "  Surrogate splits:\n",
      "      non functional          < 0.2601226  to the left,  agree=0.640, adj=0.169, (0 split)\n",
      "      functional needs repair < 0.7968178  to the left,  agree=0.611, adj=0.104, (0 split)\n",
      "\n",
      "Node number 11: 7994 observations,    complexity param=0.002555955\n",
      "  predicted class=functional               expected loss=0.4649737  P(node) =0.1682168\n",
      "    class counts:  4277  1024  2693\n",
      "   probabilities: 0.535 0.128 0.337 \n",
      "  left son=22 (1530 obs) right son=23 (6464 obs)\n",
      "  Primary splits:\n",
      "      non functional          < 0.2304196  to the left,  improve=96.56580, (0 missing)\n",
      "      functional              < 0.4756131  to the right, improve=84.39028, (0 missing)\n",
      "      functional needs repair < 0.5324612  to the right, improve=77.66877, (0 missing)\n",
      "\n",
      "Node number 20: 864 observations\n",
      "  predicted class=functional               expected loss=0.4641204  P(node) =0.01818105\n",
      "    class counts:   463   285   116\n",
      "   probabilities: 0.536 0.330 0.134 \n",
      "\n",
      "Node number 21: 1128 observations\n",
      "  predicted class=functional needs repair  expected loss=0.427305  P(node) =0.02373637\n",
      "    class counts:   281   646   201\n",
      "   probabilities: 0.249 0.573 0.178 \n",
      "\n",
      "Node number 22: 1530 observations,    complexity param=0.001335544\n",
      "  predicted class=functional               expected loss=0.3849673  P(node) =0.03219561\n",
      "    class counts:   941   355   234\n",
      "   probabilities: 0.615 0.232 0.153 \n",
      "  left son=44 (1467 obs) right son=45 (63 obs)\n",
      "  Primary splits:\n",
      "      functional              < 0.4072102  to the right, improve=23.69290, (0 missing)\n",
      "      functional needs repair < 0.5277044  to the right, improve=13.98190, (0 missing)\n",
      "      non functional          < 0.1238285  to the right, improve=11.71627, (0 missing)\n",
      "\n",
      "Node number 23: 6464 observations,    complexity param=0.002555955\n",
      "  predicted class=functional               expected loss=0.4839109  P(node) =0.1360212\n",
      "    class counts:  3336   669  2459\n",
      "   probabilities: 0.516 0.103 0.380 \n",
      "  left son=46 (4579 obs) right son=47 (1885 obs)\n",
      "  Primary splits:\n",
      "      functional              < 0.4756131  to the right, improve=66.24752, (0 missing)\n",
      "      functional needs repair < 0.5384759  to the left,  improve=45.44459, (0 missing)\n",
      "      non functional          < 0.3817678  to the left,  improve=21.20439, (0 missing)\n",
      "  Surrogate splits:\n",
      "      functional needs repair < 0.6447432  to the left,  agree=0.733, adj=0.083, (0 split)\n",
      "      non functional          < 0.4457572  to the left,  agree=0.714, adj=0.018, (0 split)\n",
      "\n",
      "Node number 44: 1467 observations\n",
      "  predicted class=functional               expected loss=0.3680982  P(node) =0.03086991\n",
      "    class counts:   927   312   228\n",
      "   probabilities: 0.632 0.213 0.155 \n",
      "\n",
      "Node number 45: 63 observations\n",
      "  predicted class=functional needs repair  expected loss=0.3174603  P(node) =0.001325702\n",
      "    class counts:    14    43     6\n",
      "   probabilities: 0.222 0.683 0.095 \n",
      "\n",
      "Node number 46: 4579 observations\n",
      "  predicted class=functional               expected loss=0.4308801  P(node) =0.09635537\n",
      "    class counts:  2606   355  1618\n",
      "   probabilities: 0.569 0.078 0.353 \n",
      "\n",
      "Node number 47: 1885 observations\n",
      "  predicted class=non functional           expected loss=0.5538462  P(node) =0.03966584\n",
      "    class counts:   730   314   841\n",
      "   probabilities: 0.387 0.167 0.446 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "summary(fitrpart)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th></th><th scope=col>functional</th><th scope=col>functional needs repair</th><th scope=col>non functional</th><th scope=col>prediction</th><th scope=col>status_group</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>1</th><td>0.9784953</td><td>0.1283513</td><td>0.008162931</td><td>functional</td><td>functional</td></tr>\n",
       "\t<tr><th scope=row>2</th><td>0.8018478</td><td>0.2651268</td><td>0.2195993</td><td>functional</td><td>functional</td></tr>\n",
       "\t<tr><th scope=row>3</th><td>0.7280951</td><td>0.5104547</td><td>0.1212882</td><td>functional</td><td>functional</td></tr>\n",
       "\t<tr><th scope=row>4</th><td>0.935521</td><td>0.1202293</td><td>0.1576795</td><td>functional</td><td>functional</td></tr>\n",
       "\t<tr><th scope=row>5</th><td>0.537815</td><td>0.1322872</td><td>0.4230001</td><td>functional</td><td>non functional</td></tr>\n",
       "\t<tr><th scope=row>6</th><td>0.5553696</td><td>0.3015835</td><td>0.5806489</td><td>non functional</td><td>non functional</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|lllll}\n",
       "  & functional & functional needs repair & non functional & prediction & status_group\\\\\n",
       "\\hline\n",
       "\t1 & 0.9784953 & 0.1283513 & 0.008162931 & functional & functional\\\\\n",
       "\t2 & 0.8018478 & 0.2651268 & 0.2195993 & functional & functional\\\\\n",
       "\t3 & 0.7280951 & 0.5104547 & 0.1212882 & functional & functional\\\\\n",
       "\t4 & 0.935521 & 0.1202293 & 0.1576795 & functional & functional\\\\\n",
       "\t5 & 0.537815 & 0.1322872 & 0.4230001 & functional & non functional\\\\\n",
       "\t6 & 0.5553696 & 0.3015835 & 0.5806489 & non functional & non functional\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "  functional functional needs repair non functional     prediction\n",
       "1  0.9784953               0.1283513    0.008162931     functional\n",
       "2  0.8018478               0.2651268    0.219599288     functional\n",
       "3  0.7280951               0.5104547    0.121288187     functional\n",
       "4  0.9355210               0.1202293    0.157679508     functional\n",
       "5  0.5378150               0.1322872    0.423000081     functional\n",
       "6  0.5553696               0.3015835    0.580648887 non functional\n",
       "    status_group\n",
       "1     functional\n",
       "2     functional\n",
       "3     functional\n",
       "4     functional\n",
       "5 non functional\n",
       "6 non functional"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predsForVoteRpart <- predsForVote\n",
    "predsForVoteRpart$prediction <- predict(fitrpart, predsForVoteRpart, type = 'class')\n",
    "head(predsForVoteRpart)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th></th><th scope=col>functional</th><th scope=col>functional needs repair</th><th scope=col>non functional</th><th scope=col>prediction</th><th scope=col>status_group</th><th scope=col>status_group.functional.needs.repair</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>1</th><td>0.9784953</td><td>0.1283513</td><td>0.008162931</td><td>FALSE</td><td>functional</td><td>0</td></tr>\n",
       "\t<tr><th scope=row>2</th><td>0.8018478</td><td>0.2651268</td><td>0.2195993</td><td>FALSE</td><td>functional</td><td>0</td></tr>\n",
       "\t<tr><th scope=row>3</th><td>0.7280951</td><td>0.5104547</td><td>0.1212882</td><td>FALSE</td><td>functional</td><td>0</td></tr>\n",
       "\t<tr><th scope=row>4</th><td>0.935521</td><td>0.1202293</td><td>0.1576795</td><td>FALSE</td><td>functional</td><td>0</td></tr>\n",
       "\t<tr><th scope=row>5</th><td>0.537815</td><td>0.1322872</td><td>0.4230001</td><td>FALSE</td><td>non functional</td><td>0</td></tr>\n",
       "\t<tr><th scope=row>6</th><td>0.5553696</td><td>0.3015835</td><td>0.5806489</td><td>FALSE</td><td>non functional</td><td>0</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|llllll}\n",
       "  & functional & functional needs repair & non functional & prediction & status_group & status_group.functional.needs.repair\\\\\n",
       "\\hline\n",
       "\t1 & 0.9784953 & 0.1283513 & 0.008162931 & FALSE & functional & 0\\\\\n",
       "\t2 & 0.8018478 & 0.2651268 & 0.2195993 & FALSE & functional & 0\\\\\n",
       "\t3 & 0.7280951 & 0.5104547 & 0.1212882 & FALSE & functional & 0\\\\\n",
       "\t4 & 0.935521 & 0.1202293 & 0.1576795 & FALSE & functional & 0\\\\\n",
       "\t5 & 0.537815 & 0.1322872 & 0.4230001 & FALSE & non functional & 0\\\\\n",
       "\t6 & 0.5553696 & 0.3015835 & 0.5806489 & FALSE & non functional & 0\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "  functional functional needs repair non functional prediction   status_group\n",
       "1  0.9784953               0.1283513    0.008162931      FALSE     functional\n",
       "2  0.8018478               0.2651268    0.219599288      FALSE     functional\n",
       "3  0.7280951               0.5104547    0.121288187      FALSE     functional\n",
       "4  0.9355210               0.1202293    0.157679508      FALSE     functional\n",
       "5  0.5378150               0.1322872    0.423000081      FALSE non functional\n",
       "6  0.5553696               0.3015835    0.580648887      FALSE non functional\n",
       "  status_group.functional.needs.repair\n",
       "1                                    0\n",
       "2                                    0\n",
       "3                                    0\n",
       "4                                    0\n",
       "5                                    0\n",
       "6                                    0"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "       \n",
       "        FALSE  TRUE\n",
       "  FALSE 43707  2869\n",
       "  TRUE    361   585"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predsForVoteGlm <- predsForVote\n",
    "predsForVoteGlm$prediction <- predict(fitglm, predsForVoteGlm, type = 'response') > 0.5\n",
    "head(predsForVoteGlm)\n",
    "table(predsForVoteGlm$prediction, predsForVoteGlm$status_group == 'functional needs repair')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Confusion Matrix and Statistics\n",
       "\n",
       "                         Reference\n",
       "Prediction                functional functional needs repair non functional\n",
       "  functional                   20503                    1035           4263\n",
       "  functional needs repair       3921                    2165           2460\n",
       "  non functional                1384                     254          11537\n",
       "\n",
       "Overall Statistics\n",
       "                                          \n",
       "               Accuracy : 0.7198          \n",
       "                 95% CI : (0.7157, 0.7238)\n",
       "    No Information Rate : 0.5431          \n",
       "    P-Value [Acc > NIR] : < 2.2e-16       \n",
       "                                          \n",
       "                  Kappa : 0.5214          \n",
       " Mcnemar's Test P-Value : < 2.2e-16       \n",
       "\n",
       "Statistics by Class:\n",
       "\n",
       "                     Class: functional Class: functional needs repair\n",
       "Sensitivity                     0.7944                        0.62681\n",
       "Specificity                     0.7560                        0.85520\n",
       "Pos Pred Value                  0.7947                        0.25333\n",
       "Neg Pred Value                  0.7558                        0.96693\n",
       "Prevalence                      0.5431                        0.07268\n",
       "Detection Rate                  0.4314                        0.04556\n",
       "Detection Prevalence            0.5429                        0.17983\n",
       "Balanced Accuracy               0.7752                        0.74101\n",
       "                     Class: non functional\n",
       "Sensitivity                         0.6318\n",
       "Specificity                         0.9440\n",
       "Pos Pred Value                      0.8757\n",
       "Neg Pred Value                      0.8043\n",
       "Prevalence                          0.3842\n",
       "Detection Rate                      0.2428\n",
       "Detection Prevalence                0.2772\n",
       "Balanced Accuracy                   0.7879"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusionMatrix(predictions$prediction, training$status_group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Confusion Matrix and Statistics\n",
       "\n",
       "                         Reference\n",
       "Prediction                functional functional needs repair non functional\n",
       "  functional                   22790                    1981           4574\n",
       "  functional needs repair        295                     689            207\n",
       "  non functional                2723                     784          13479\n",
       "\n",
       "Overall Statistics\n",
       "                                          \n",
       "               Accuracy : 0.7777          \n",
       "                 95% CI : (0.7739, 0.7814)\n",
       "    No Information Rate : 0.5431          \n",
       "    P-Value [Acc > NIR] : < 2.2e-16       \n",
       "                                          \n",
       "                  Kappa : 0.577           \n",
       " Mcnemar's Test P-Value : < 2.2e-16       \n",
       "\n",
       "Statistics by Class:\n",
       "\n",
       "                     Class: functional Class: functional needs repair\n",
       "Sensitivity                     0.8831                        0.19948\n",
       "Specificity                     0.6981                        0.98861\n",
       "Pos Pred Value                  0.7766                        0.57851\n",
       "Neg Pred Value                  0.8340                        0.94032\n",
       "Prevalence                      0.5431                        0.07268\n",
       "Detection Rate                  0.4796                        0.01450\n",
       "Detection Prevalence            0.6175                        0.02506\n",
       "Balanced Accuracy               0.7906                        0.59404\n",
       "                     Class: non functional\n",
       "Sensitivity                         0.7382\n",
       "Specificity                         0.8802\n",
       "Pos Pred Value                      0.7935\n",
       "Neg Pred Value                      0.8434\n",
       "Prevalence                          0.3842\n",
       "Detection Rate                      0.2836\n",
       "Detection Prevalence                0.3574\n",
       "Balanced Accuracy                   0.8092"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusionMatrix(predsForVoteRpart$prediction, training$status_group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th></th><th scope=col>functional</th><th scope=col>functional needs repair</th><th scope=col>non functional</th><th scope=col>prediction</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>1</th><td>0.6750547</td><td>0.5143671</td><td>0.1702349</td><td>functional</td></tr>\n",
       "\t<tr><th scope=row>2</th><td>0.0001385644</td><td>0.1306848</td><td>0.9909738</td><td>non functional</td></tr>\n",
       "\t<tr><th scope=row>3</th><td>0.8970092</td><td>0.1046726</td><td>0.06849791</td><td>functional</td></tr>\n",
       "\t<tr><th scope=row>4</th><td>0.947248</td><td>0.1014085</td><td>0.02019313</td><td>functional</td></tr>\n",
       "\t<tr><th scope=row>5</th><td>0.5186912</td><td>0.5318944</td><td>0.3386338</td><td>functional needs repair</td></tr>\n",
       "\t<tr><th scope=row>6</th><td>0.7460559</td><td>0.6597764</td><td>0.02066555</td><td>functional</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|llll}\n",
       "  & functional & functional needs repair & non functional & prediction\\\\\n",
       "\\hline\n",
       "\t1 & 0.6750547 & 0.5143671 & 0.1702349 & functional\\\\\n",
       "\t2 & 0.0001385644 & 0.1306848 & 0.9909738 & non functional\\\\\n",
       "\t3 & 0.8970092 & 0.1046726 & 0.06849791 & functional\\\\\n",
       "\t4 & 0.947248 & 0.1014085 & 0.02019313 & functional\\\\\n",
       "\t5 & 0.5186912 & 0.5318944 & 0.3386338 & functional needs repair\\\\\n",
       "\t6 & 0.7460559 & 0.6597764 & 0.02066555 & functional\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "Source: local data frame [6 x 4]\n",
       "\n",
       "    functional functional needs repair non functional              prediction\n",
       "         (dbl)                   (dbl)          (dbl)                  (fctr)\n",
       "1 0.6750547095               0.5143671     0.17023494              functional\n",
       "2 0.0001385644               0.1306848     0.99097383          non functional\n",
       "3 0.8970092357               0.1046726     0.06849791              functional\n",
       "4 0.9472479961               0.1014085     0.02019313              functional\n",
       "5 0.5186912412               0.5318944     0.33863378 functional needs repair\n",
       "6 0.7460558890               0.6597764     0.02066555              functional"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th></th><th scope=col>functional</th><th scope=col>functional needs repair</th><th scope=col>non functional</th><th scope=col>prediction</th><th scope=col>status_group</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>1</th><td>0.6750547</td><td>0.5143671</td><td>0.1702349</td><td>functional</td><td>functional</td></tr>\n",
       "\t<tr><th scope=row>2</th><td>0.0001385644</td><td>0.1306848</td><td>0.9909738</td><td>non functional</td><td>non functional</td></tr>\n",
       "\t<tr><th scope=row>3</th><td>0.8970092</td><td>0.1046726</td><td>0.06849791</td><td>functional</td><td>non functional</td></tr>\n",
       "\t<tr><th scope=row>4</th><td>0.947248</td><td>0.1014085</td><td>0.02019313</td><td>functional</td><td>functional</td></tr>\n",
       "\t<tr><th scope=row>5</th><td>0.5186912</td><td>0.5318944</td><td>0.3386338</td><td>functional needs repair</td><td>functional</td></tr>\n",
       "\t<tr><th scope=row>6</th><td>0.7460559</td><td>0.6597764</td><td>0.02066555</td><td>functional</td><td>functional</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|lllll}\n",
       "  & functional & functional needs repair & non functional & prediction & status_group\\\\\n",
       "\\hline\n",
       "\t1 & 0.6750547 & 0.5143671 & 0.1702349 & functional & functional\\\\\n",
       "\t2 & 0.0001385644 & 0.1306848 & 0.9909738 & non functional & non functional\\\\\n",
       "\t3 & 0.8970092 & 0.1046726 & 0.06849791 & functional & non functional\\\\\n",
       "\t4 & 0.947248 & 0.1014085 & 0.02019313 & functional & functional\\\\\n",
       "\t5 & 0.5186912 & 0.5318944 & 0.3386338 & functional needs repair & functional\\\\\n",
       "\t6 & 0.7460559 & 0.6597764 & 0.02066555 & functional & functional\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "    functional functional needs repair non functional              prediction\n",
       "1 0.6750547095               0.5143671     0.17023494              functional\n",
       "2 0.0001385644               0.1306848     0.99097383          non functional\n",
       "3 0.8970092357               0.1046726     0.06849791              functional\n",
       "4 0.9472479961               0.1014085     0.02019313              functional\n",
       "5 0.5186912412               0.5318944     0.33863378 functional needs repair\n",
       "6 0.7460558890               0.6597764     0.02066555              functional\n",
       "    status_group\n",
       "1     functional\n",
       "2 non functional\n",
       "3 non functional\n",
       "4     functional\n",
       "5     functional\n",
       "6     functional"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th></th><th scope=col>functional</th><th scope=col>functional needs repair</th><th scope=col>non functional</th><th scope=col>prediction</th><th scope=col>status_group</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>1</th><td>0.6750547</td><td>0.5143671</td><td>0.1702349</td><td>functional</td><td>functional</td></tr>\n",
       "\t<tr><th scope=row>2</th><td>0.0001385644</td><td>0.1306848</td><td>0.9909738</td><td>non functional</td><td>non functional</td></tr>\n",
       "\t<tr><th scope=row>3</th><td>0.8970092</td><td>0.1046726</td><td>0.06849791</td><td>functional</td><td>non functional</td></tr>\n",
       "\t<tr><th scope=row>4</th><td>0.947248</td><td>0.1014085</td><td>0.02019313</td><td>functional</td><td>functional</td></tr>\n",
       "\t<tr><th scope=row>5</th><td>0.5186912</td><td>0.5318944</td><td>0.3386338</td><td>functional</td><td>functional</td></tr>\n",
       "\t<tr><th scope=row>6</th><td>0.7460559</td><td>0.6597764</td><td>0.02066555</td><td>functional</td><td>functional</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|lllll}\n",
       "  & functional & functional needs repair & non functional & prediction & status_group\\\\\n",
       "\\hline\n",
       "\t1 & 0.6750547 & 0.5143671 & 0.1702349 & functional & functional\\\\\n",
       "\t2 & 0.0001385644 & 0.1306848 & 0.9909738 & non functional & non functional\\\\\n",
       "\t3 & 0.8970092 & 0.1046726 & 0.06849791 & functional & non functional\\\\\n",
       "\t4 & 0.947248 & 0.1014085 & 0.02019313 & functional & functional\\\\\n",
       "\t5 & 0.5186912 & 0.5318944 & 0.3386338 & functional & functional\\\\\n",
       "\t6 & 0.7460559 & 0.6597764 & 0.02066555 & functional & functional\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "    functional functional needs repair non functional     prediction\n",
       "1 0.6750547095               0.5143671     0.17023494     functional\n",
       "2 0.0001385644               0.1306848     0.99097383 non functional\n",
       "3 0.8970092357               0.1046726     0.06849791     functional\n",
       "4 0.9472479961               0.1014085     0.02019313     functional\n",
       "5 0.5186912412               0.5318944     0.33863378     functional\n",
       "6 0.7460558890               0.6597764     0.02066555     functional\n",
       "    status_group\n",
       "1     functional\n",
       "2 non functional\n",
       "3 non functional\n",
       "4     functional\n",
       "5     functional\n",
       "6     functional"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predsTestingDf <- data.frame('functional' = predsTesting$status_group.functional,\n",
    "                      'needrepair' = predsTesting$`status_group.functional.needs.repair balanced`,\n",
    "                      'nonfunctional' = predsTesting$status_group.non.functional)\n",
    "\n",
    "colnames(predsTestingDf) <- c('functional', 'functional needs repair', 'non functional')\n",
    "predictionsTesting <- predsTestingDf %>%\n",
    "                  rowwise() %>% \n",
    "                  mutate(prediction=predictionLevels[which.max(c(functional, `functional needs repair`, `non functional`))])\n",
    "\n",
    "head(predictionsTesting)\n",
    "predsForVoteTest <- cbind(predictionsTesting, testing$status_group)\n",
    "colnames(predsForVoteTest) <- c('functional', 'functional needs repair', 'non functional', 'prediction', 'status_group')\n",
    "head(predsForVoteTest)\n",
    "\n",
    "predsForVoteRpart.test <- predsForVoteTest\n",
    "predsForVoteRpart.test$prediction <- predict(fitrpart, predsForVoteRpart.test, type = 'class')\n",
    "head(predsForVoteRpart.test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Confusion Matrix and Statistics\n",
       "\n",
       "                         Reference\n",
       "Prediction                functional functional needs repair non functional\n",
       "  functional                    5660                     518           1193\n",
       "  functional needs repair         54                     154             45\n",
       "  non functional                 737                     191           3326\n",
       "\n",
       "Overall Statistics\n",
       "                                         \n",
       "               Accuracy : 0.7695         \n",
       "                 95% CI : (0.7618, 0.777)\n",
       "    No Information Rate : 0.5431         \n",
       "    P-Value [Acc > NIR] : < 2.2e-16      \n",
       "                                         \n",
       "                  Kappa : 0.5599         \n",
       " Mcnemar's Test P-Value : < 2.2e-16      \n",
       "\n",
       "Statistics by Class:\n",
       "\n",
       "                     Class: functional Class: functional needs repair\n",
       "Sensitivity                     0.8774                        0.17845\n",
       "Specificity                     0.6847                        0.99101\n",
       "Pos Pred Value                  0.7679                        0.60870\n",
       "Neg Pred Value                  0.8245                        0.93901\n",
       "Prevalence                      0.5431                        0.07266\n",
       "Detection Rate                  0.4765                        0.01297\n",
       "Detection Prevalence            0.6206                        0.02130\n",
       "Balanced Accuracy               0.7811                        0.58473\n",
       "                     Class: non functional\n",
       "Sensitivity                         0.7287\n",
       "Specificity                         0.8731\n",
       "Pos Pred Value                      0.7819\n",
       "Neg Pred Value                      0.8376\n",
       "Prevalence                          0.3842\n",
       "Detection Rate                      0.2800\n",
       "Detection Prevalence                0.3581\n",
       "Balanced Accuracy                   0.8009"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusionMatrix(predsForVoteRpart.test$prediction, testing$status_group)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.2.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
