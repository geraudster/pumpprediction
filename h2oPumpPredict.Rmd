# Pump it up with H2O and R

![H2O Logo](pics/h2o-logo_360.png)
Competition link: http://www.drivendata.org/competitions/7/page/23/

*TODO: small description

## Data codebook

Let's load the data in R and see how it looks like:
```{r}
trainset.values <- read.csv('trainset_values.csv')
trainset.labels <- read.csv('trainset_labels.csv')
testset.values <- read.csv('testset_values.csv')
```

The dataset contains `r nrow(trainset.values)` observations caracterized by `r ncol(trainset.values)` variables.
Below is a sample:
```{r}
str(trainset.values)
```

Now let's see the data repartition depending on the label to be predicted (functional, non functional, need repairs):
```{r, echo = FALSE, warning = FALSE, message = FALSE, cache = TRUE, fig.width=10}
library(ggplot2)
library(gridExtra)
boxplots <- qplot(trainset.labels$status_group, 
                  fill = trainset.labels$status_group) +
  xlab('Status') +
  scale_fill_manual(values=c("green", "orange", "red"), 
                     name="Status") +
  ylab('Count') +
  ggtitle('Water pump status') +
  theme(legend.position="none")

library(plyr)
library(ggmap)
filtered.data <- join(trainset.values, trainset.labels)
filtered.data <- subset(filtered.data, longitude != 0)
bbox <- make_bbox(longitude, latitude, data = filtered.data)
map <- get_map(bbox, source = 'osm')
plot.map <- ggmap(map)
# map <- map + stat_density2d(aes(x=longitude, y=latitude, fill = ..level.., alpha = ..level.., colour = status_group),
#                             data = filtered.data,
#                             size = 0.01, bins = 16, geom = "polygon")
plot.map <- plot.map + geom_point(aes(x=longitude, y=latitude, color=status_group), data = filtered.data) +
  scale_color_manual(values=c("green", "orange", "red"), 
                     name="Status")
grid.arrange(boxplots, plot.map, nrow = 1, ncol = 2, widths = c(1,2))
```

Here we can see two things:

* first, classes are imbalanced, there are far less 'need repair' than other classes
* second, the map seems to indicate that geographic position has an importance on the pump status


## H2O

### Pre-requisites

* R
* Java: JRE at least 1.6 (1.7 recommended)

### H2O Installation from R

The following command wil install latest version of H2O:
```{r, eval = FALSE}
install.packages("h2o", type = "source", repos = (c("http://h2o-release.s3.amazonaws.com/h2o/rel-tibshirani/8/R")))
```

### Your first instance

Starting a local instance is quite simple:
```{r, cache = TRUE}
library(h2o)
localH2O <- h2o.init()
```

You can also configure some extra parameters like RAM, thread number:
```{r, eval = FALSE}
localH2O <- h2o.init(nthreads = 12, max_mem_size = '24G')
```

This will start a local instance running on 12 threads and 24GB RAM. There are also option to connect on remote cluster.

### Loading data into H2O

```{r, cache = TRUE}
trainset.hex <- h2o.uploadFile(path = 'trainset_values.csv', destination_frame = 'trainset.hex', sep = ',', header = TRUE)
labels.hex <- h2o.uploadFile(path = 'trainset_labels.csv', destination_frame = 'labels.hex', sep = ',', header = TRUE)

trainsetFull.hex <- h2o.merge(trainset.hex, labels.hex)
```

Data should be loaded in H2O now, we can try a few commands:

```{r, cache = TRUE}
head(trainsetFull.hex)
summary(trainsetFull.hex)
```

### Machine Learning

Let's split the data to validate our model:
```{r, cache = TRUE}
splits <- h2o.splitFrame(trainsetFull.hex, 0.8)
train <- splits[[1]]
test <- splits[[2]]

dim(train)
dim(test)
```

Now we'll check label proportion:
```{r, cache = TRUE}
prop.table(table(as.vector(train$status_group)))
prop.table(table(as.vector(test$status_group)))
```


We will restrict the list of predictors as some nominal values contain lots of categories ('wpt_name', 'subvillage', 'scheme_name', 'installer', 'ward', 'funder'):

```{r, cache = TRUE}
allVariables <- colnames(train)
predictors <- colnames(train)[!(allVariables %in% c('id', 'wpt_name', 'subvillage', 'scheme_name', 'installer', 'ward', 'funder', 'status_group', 'recorded_by'))]
```


Now we are going to train our random forest on the dataset:

```{r, cache = TRUE}
rfModel <- h2o.randomForest(predictors, 'status_group', train)
```

Let's validate it:
```{r, cache = TRUE}
confusionMatrix <- h2o.confusionMatrix(rfModel, newdata = test)

# Render table
library(knitr)
kable(confusionMatrix)
```


### Results

### Shutting down

```{r, cache = TRUE}
h2o.shutdown(prompt = FALSE)
```


